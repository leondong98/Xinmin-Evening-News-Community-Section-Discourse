---
title: Seminar1

---

# ç ”è®¨ä¼š1: æ–‡æœ¬ä½œä¸ºæ•°æ®A

è®²åº§äººï¼šHanxu hanxu.dong.21@ucl.ac.uk

<p>
  <a href="https://github.com/leondong98/Text-Analysis-Workshop/raw/main/Data/mft_dictionary.csv" 
     style="display:inline-block; background-color:#4CAF50; color:white; padding:10px 20px; text-decoration:none; margin-right:10px; border-radius:5px;">
    Seminar data 1
  </a>

  <a href="https://github.com/leondong98/Text-Analysis-Workshop/raw/main/Data/mft_texts.csv" 
     style="display:inline-block; background-color:#F57C00; color:white; padding:10px 20px; text-decoration:none; border-radius:5px;">
    Seminar data 2
  </a>
</p>



## 1.1 ç ”è®¨ä¼šä»‹ç»
æœ¬æ¬¡ç ”è®¨è¯¾æ—¨åœ¨å¼•å¯¼å­¦ç”Ÿå®é™…æ“ä½œ [quanteda](https://quanteda.io) å¥—ä»¶åŠè‹¥å¹²ç›¸å…³ R è¯­è¨€ç¨‹åºåŒ…ã€‚è¯¾ç¨‹é‡ç‚¹åŒ…æ‹¬ï¼šæ¢ç´¢è¯¥å¥—ä»¶çš„åŸºæœ¬åŠŸèƒ½ï¼Œå°†æ–‡æœ¬å¯¼å…¥å¹¶è½¬æ¢ä¸ºè¯­æ–™åº“ï¼ˆcorpusï¼‰å¯¹è±¡æ ¼å¼ï¼Œå­¦ä¹ å¦‚ä½•å°†æ–‡æœ¬è½¬åŒ–ä¸ºæ–‡æ¡£-ç‰¹å¾çŸ©é˜µï¼ˆdocument-feature matrices, DFMï¼‰ï¼Œåœ¨æ­¤åŸºç¡€ä¸Šå¼€å±•æè¿°æ€§åˆ†æï¼Œå¹¶å°è¯•æ„å»ºä¸éªŒè¯å­—å…¸å·¥å…·ï¼ˆdictionariesï¼‰ä»¥æ”¯æŒæ–‡æœ¬åˆ†æç ”ç©¶ã€‚

å¯¹äºRè¯­è¨€ï¼Œè¯·å‚è€ƒæˆ‘ä»¬day1è®¨è®ºçš„ R è¯­è¨€å…¥é—¨ï¼ˆé“¾æ¥æ–½å·¥ä¸­...ï¼‰ã€‚

## 1.2 é“å¾·æƒ…æ„Ÿçš„æµ‹é‡
â€œé“å¾·åŸºç¡€ç†è®ºâ€ï¼ˆMoral Foundations Theoryï¼‰æ˜¯ä¸€ç§ç¤¾ä¼šå¿ƒç†å­¦ç†è®ºï¼Œè®¤ä¸ºäººä»¬çš„é“å¾·åˆ¤æ–­åŸºäºäº”ç§å½¼æ­¤ç‹¬ç«‹çš„é“å¾·ä»·å€¼ã€‚è¿™äº”ç§åŸºç¡€ï¼ˆå¦‚ä¸‹è¡¨æ‰€åˆ—ï¼‰åˆ†åˆ«æ˜¯ï¼šå…³æ€€/ä¼¤å®³ï¼ˆcare/harmï¼‰ã€å…¬æ­£/æ¬ºéª—ï¼ˆfairness/cheatingï¼‰ã€å¿ è¯š/èƒŒå›ï¼ˆloyalty/betrayalï¼‰ã€æƒå¨/é¢ è¦†ï¼ˆauthority/subversionï¼‰ä»¥åŠç¥åœ£/å •è½ï¼ˆsanctity/degradationï¼‰ã€‚

æ ¹æ®è¯¥ç†è®ºï¼Œäººä»¬åœ¨é¢å¯¹ä¸åŒçš„è®®é¢˜å’Œæƒ…å¢ƒæ—¶ï¼Œä¼šä¾æ®è¿™äº›é“å¾·åŸºç¡€è¿›è¡Œåˆ¤æ–­ã€‚æ­¤å¤–ï¼Œè¯¥ç†è®ºæŒ‡å‡ºï¼Œä¸åŒä¸ªä½“å¯¹äºè¿™äº”ç§ä»·å€¼çš„é‡è§†ç¨‹åº¦å­˜åœ¨å·®å¼‚ï¼Œè€Œè¿™ç§å·®å¼‚æœ‰åŠ©äºè§£é‡Šäººä»¬åœ¨é“å¾·åˆ¤æ–­ä¸Šçš„æ–‡åŒ–æ€§å’Œä¸ªä½“æ€§å·®å¼‚ã€‚

ä¸‹è¡¨æä¾›äº†è¿™äº”é¡¹é“å¾·åŸºç¡€çš„ç®€è¦æ¦‚è¿°ï¼š

| åŸºç¡€ | ä»‹ç»                                                                 |
|------------|------------------------------------------------------------------------------|
| Care       | Concern for caring behaviour, kindness, compassion                          |
| Fairness   | Concern for fairness, justice, trustworthiness                               |
| Authority  | Concern for obedience and deference to figures of authority (religious, state, etc) |
| Loyalty    | Concern for loyalty, patriotism, self-sacrifice                              |
| Sanctity   | Concern for temperance, chastity, piety, cleanliness                         |


æˆ‘ä»¬èƒ½å¦ä»æ–‡æœ¬ä¸­è¯†åˆ«å‡ºé“å¾·åŸºç¡€çš„ä½¿ç”¨ï¼Ÿåœ¨æ”¿æ²»è®ºè¾©ä¸­ï¼Œé“å¾·æ¡†æ¶ä¸ä¿®è¾ç­–ç•¥å‘æŒ¥ç€é‡è¦ä½œç”¨ã€‚è€Œæ ¹æ·±è’‚å›ºçš„é“å¾·åˆ†æ­§å¸¸è¢«è®¤ä¸ºæ˜¯æ”¿æ²»æåŒ–ï¼Œå°¤å…¶æ˜¯åœ¨ç½‘ç»œç¯å¢ƒä¸­åŠ å‰§çš„é‡è¦æ ¹æºã€‚åœ¨æˆ‘ä»¬æ¢è®¨è¯¸å¦‚â€œä¸åŒæ”¿æ²»ç«‹åœºçš„ç¾¤ä½“åœ¨é“å¾·è¯­è¨€ä½¿ç”¨ä¸Šæ˜¯å¦å­˜åœ¨æ˜¾è‘—å·®å¼‚â€ï¼ˆ[æ¡ˆä¾‹](https://psycnet.apa.org/record/2009-05192-002?doi=1)ï¼‰æˆ–â€œé“å¾·è®ºè¯æ˜¯å¦æœ‰åŠ©äºç¼“è§£æ”¿æ²»æåŒ–â€ï¼ˆ[æ¡ˆä¾‹](http://kmunger.github.io/pdfs/jmp.pdf)ï¼‰ç­‰å…³é”®ç ”ç©¶é—®é¢˜ä¹‹å‰ï¼Œå‰ææ˜¯æˆ‘ä»¬å¿…é¡»èƒ½å¤Ÿåœ¨å¤§è§„æ¨¡æ–‡æœ¬ä¸­å¯¹é“å¾·è¯­è¨€çš„ä½¿ç”¨è¿›è¡Œæœ‰æ•ˆæµ‹é‡ã€‚

å› æ­¤ï¼Œåœ¨æœ¬æ¬¡ç ”è®¨è¯¾ä¸­ï¼Œæˆ‘ä»¬å°†é‡‡ç”¨ä¸€ç§ç®€åŒ–çš„å­—å…¸åˆ†ææ–¹æ³•ï¼Œä»¥è¡¡é‡ä¸€ç»„åœ¨çº¿æ–‡æœ¬ä¸­æ‰€ä½“ç°çš„é“å¾·è¯­è¨€ä½¿ç”¨ç¨‹åº¦ã€‚è¯¥æ–¹æ³•å°†ä¾æ®â€œé“å¾·åŸºç¡€ç†è®ºâ€ä¸­æ‰€ç•Œå®šçš„ä¸åŒç±»å‹é“å¾·ä»·å€¼ï¼Œè¯„ä¼°æ–‡æœ¬å†…å®¹ä¸ç›¸åº”é“å¾·æ¡†æ¶ä¹‹é—´çš„å¥‘åˆç¨‹åº¦ã€‚


## 1.3.1 æ•°æ®é›†

åœ¨æœ¬èŠ‚ç ”è®¨ä¼šä¸­ï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨ä¸¤ä¸ªæ•°æ®é›†ï¼š

**1. Moral Foundations Dictionary** â€“ ``mft_dictionary.csv``

  - è¯¥æ•°æ®é›†æ”¶å½•äº†ä¸€ç³»åˆ—è¢«è®¤ä¸ºèƒ½æŒ‡ç¤ºæ–‡æœ¬ä¸­ä¸åŒé“å¾·å…³åˆ‡çš„è¯æ±‡åˆ—è¡¨ã€‚è¯¥å­—å…¸æœ€åˆç”± Jesse Graham ä¸ Jonathan Haidt å¼€å‘ï¼Œå¹¶åœ¨å…¶[ç›¸å…³è®ºæ–‡](https://psycnet.apa.org/record/2009-05192-002?doi=1)ä¸­æœ‰æ›´ä¸ºè¯¦å°½çš„ä»‹ç»ã€‚
  - å­—å…¸å…±åˆ’åˆ†ä¸ºäº”ç±»é“å¾·å…³åˆ‡ç»´åº¦ï¼šæƒå¨ï¼ˆauthorityï¼‰ã€å¿ è¯šï¼ˆloyaltyï¼‰ã€ç¥åœ£ï¼ˆsanctityï¼‰ã€å…¬æ­£ï¼ˆfairnessï¼‰ä¸å…³æ€€ï¼ˆcareï¼‰ï¼Œæ¯ä¸€ç±»å‡å¯¹åº”ä¸€ç»„ç‰¹å®šçš„ä»£è¡¨æ€§è¯æ±‡ï¼Œç”¨äºè¯†åˆ«è¯¥ç±»é“å¾·è¯­ä¹‰åœ¨æ–‡æœ¬ä¸­çš„ä½“ç°ã€‚

2. **Moral Foundations Reddit Corpus** â€“ ``mft_texts.csv``

 - æœ¬æ–‡ä»¶åŒ…å« 17,886 æ¡è‹±æ–‡ Reddit è¯„è®ºï¼Œè¿™äº›è¯„è®ºç”± 11 ä¸ªä¸åŒçš„å­ç‰ˆå—ï¼ˆsubredditsï¼‰ä¸­ç²¾é€‰è€Œæ¥ã€‚è¯„è®ºå†…å®¹æ¶µç›–å¤šç§ä¸åŒä¸»é¢˜ã€‚æ­¤å¤–ï¼Œè¯¥æ•°æ®é›†è¿˜åŒ…å«ç”±ä¸“ä¸šæ ‡æ³¨å‘˜æ‰‹å·¥å®Œæˆçš„æ³¨é‡Šï¼Œæ ‡æ³¨ä¾æ®ä¸ºâ€œé“å¾·åŸºç¡€ç†è®ºâ€ä¸­å®šä¹‰çš„å„ç±»é“å¾·å…³åˆ‡ç»´åº¦ã€‚

åœ¨ä¸‹è½½å¹¶å¦¥å–„ä¿å­˜è¿™äº›æ•°æ®æ–‡ä»¶åï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä»¥ä¸‹Rè¯­è¨€æŒ‡ä»¤å°†å…¶è½½å…¥å·¥ä½œç¯å¢ƒï¼š

```r
mft_dictionary_words <- read_csv("mft_dictionary.csv")
mft_texts <- read_csv("mft_texts.csv")
```


## 1.3.2 Packages
åœ¨å¼€å§‹seminaræ—¶ï¼Œæˆ‘ä»¬éœ€è¦å®‰è£…å¹¶åŠ è½½ä»¥ä¸‹Rè¯­è¨€ç¨‹åºåŒ…ã€‚

è¯·è¿è¡Œä»¥ä¸‹ä»£ç è¡Œä»¥å®Œæˆè¿™äº›ç¨‹åºåŒ…çš„å®‰è£…ã€‚**è¯·æ³¨æ„ï¼Œç¨‹åºåŒ…ä»…éœ€åœ¨æœ¬æœºå®‰è£…ä¸€æ¬¡ï¼›å®‰è£…å®Œæˆåï¼Œå°±å¯ä»¥åˆ é™¤è¿™äº›å®‰è£…æŒ‡ä»¤ï¼š**

```r
install.packages("tidyverse") # Set of packages helpful for data manipulation
install.packages("quanteda") # Main quanteda package
install.packages("quanteda.textplots") # Package with helpful plotting functions
install.packages("quanteda.textstats") # Package with helpful statistical functions
install.packages("remotes") # Package for installing other packages
remotes::install_github("kbenoit/quanteda.dictionaries")
```

åœ¨å®Œæˆä¸Šè¿°ç¨‹åºåŒ…çš„å®‰è£…åï¼Œæˆ‘ä»¬è¿˜éœ€è¦åŠ è½½è¿™äº›ç¨‹åºåŒ…ï¼Œä»¥ä¾¿åœ¨R Studioä¸­ä½¿ç”¨å…¶æ‰€åŒ…å«çš„å„ç±»å‡½æ•°ã€‚

æ¯å½“æˆ‘ä»¬å¸Œæœ›ä½¿ç”¨è¿™äº›ç¨‹åºåŒ…çš„å‡½æ•°æ—¶ï¼Œéƒ½éœ€è¦è¿è¡Œä»¥ä¸‹ä»£ç è¡Œæ¥åŠ è½½å®ƒä»¬ï¼ˆæ­¤æ“ä½œåœ¨æ¯æ¬¡æ–°çš„ R ä¼šè¯ä¸­éƒ½éœ€é‡å¤æ‰§è¡Œï¼‰ï¼š

```r
library(tidyverse)
library(quanteda)
library(quanteda.textplots)
library(quanteda.textstats)
library(quanteda.dictionaries)
```


## 1.4 å»ºç«‹ä¸€ä¸ªCorpus

### 1.4.1 æ€ä¹ˆå¯»æ±‚å¸®åŠ©ï¼Ÿ

ç”¨Rç¼–ç¨‹å¾€å¾€æ˜¯ä¸€ä¸ªä»¤äººæ²®ä¸§çš„ç»å†ã€‚å¹¸è¿çš„æ˜¯ï¼Œå½“æˆ‘ä»¬é‡åˆ°å›°éš¾æ—¶ï¼Œæœ‰å¾ˆå¤šæ–¹æ³•å¯ä»¥å¯»æ±‚å¸®åŠ©ã€‚

 - å®˜æ–¹ç½‘ç«™ [http://quanteda.io](http://quanteda.io) æä¾›äº†è¯¦å°½çš„æ–‡æ¡£ä¸ä½¿ç”¨è¯´æ˜ã€‚
 - ä½ å¯ä»¥é€šè¿‡è¾“å…¥ ``?function_name`` çš„å½¢å¼ï¼ŒæŸ¥é˜…ä»»æ„å‡½æ•°çš„å¸®åŠ©æ–‡æ¡£ã€‚
 - æ­¤å¤–ï¼Œè¿˜å¯ä»¥ä½¿ç”¨ ``example()`` å‡½æ•°æ¥è¿è¡ŒæŸä¸€å‡½æ•°çš„ç¤ºä¾‹ä»£ç ï¼Œä»¥è§‚å¯Ÿå…¶å…·ä½“çš„ç”¨æ³•ä¸æ•ˆæœã€‚

ä¾‹å¦‚ï¼Œè‹¥è¦æŸ¥é˜… ``corpus()`` å‡½æ•°çš„å¸®åŠ©æ–‡æ¡£ï¼Œå¯ä½¿ç”¨ä»¥ä¸‹ä»£ç ï¼š

```r
?corpus
```

### 1.4.2 å»ºç«‹ä¸€ä¸ªcorpusåŠcorpusç»“æ„

åœ¨ ``quanteda`` ä¸­ï¼Œcorpus å¯¹è±¡æ˜¯æˆ‘ä»¬å¼€å±•ä¸€åˆ‡æ–‡æœ¬åˆ†æå·¥ä½œçš„åŸºç¡€ã€‚å› æ­¤ï¼Œåœ¨å°†æ–‡æœ¬æ•°æ®åŠ è½½è‡³ R ç¯å¢ƒåï¼Œé¦–è¦æ­¥éª¤æ˜¯ä½¿ç”¨ ``corpus()`` å‡½æ•°å°†å…¶è½¬æ¢ä¸ºè¯­æ–™åº“æ ¼å¼ã€‚

1. åˆ›å»ºè¯­æ–™åº“æœ€ç®€å•çš„æ–¹å¼ï¼Œæ˜¯ç›´æ¥ä½¿ç”¨ R å…¨å±€ç¯å¢ƒä¸­å·²æœ‰çš„ä¸€ç»„æ–‡æœ¬å¯¹è±¡ã€‚åœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬å·²åŠ è½½ ``mft_texts.csv`` æ–‡ä»¶ï¼Œå¹¶å°†å…¶å­˜å‚¨ä¸º ``mft_texts`` å¯¹è±¡ã€‚æˆ‘ä»¬å¯ä»¥å…ˆæŸ¥çœ‹è¿™ä¸ªå¯¹è±¡çš„å†…å®¹ï¼Œäº†è§£å…¶ç»“æ„ã€‚è¯·ä½¿ç”¨ ``head()`` å‡½æ•°ä½œç”¨äº ``mft_texts`` å¯¹è±¡ï¼Œå¹¶è®°å½•å…¶è¾“å‡ºç»“æœã€‚æ€è€ƒï¼šå“ªä¸ªå˜é‡å­—æ®µåŒ…å«äº† Reddit è¯„è®ºçš„æ­£æ–‡æ–‡æœ¬ï¼Ÿ


```r
head(mft_texts)
```

<details>
<summary>Click to show output</summary>

<pre style="overflow-x: auto; max-height: 400px; white-space: pre; font-family: monospace; background-color: #f8f8f8; padding: 1em; border-radius: 6px;">

# A tibble: 6 Ã— 9
  ...1 text              subreddit  care authority loyalty sanctity fairness non_mor
  <dbl> <chr>            <chr>      <lgl> <lgl>     <lgl>   <lgl>    <lgl>    <lgl>   
1 1     Alternatiâ€¦       worldnews  FALSE FALSE     FALSE   FALSE    FALSE    TRUE
2 2     Dr. Roberâ€¦       politics   FALSE TRUE      FALSE   FALSE    TRUE     TRUE
3 3     If you prâ€¦       worldnews  FALSE FALSE     FALSE   FALSE    FALSE    TRUE
4 4     Ben Judahâ€¦       geopolitâ€¦ FALSE TRUE      FALSE   FALSE    TRUE     FALSE
5 5     Ergo, heâ€¦        neoliberâ€¦ FALSE FALSE     TRUE    FALSE    FALSE    TRUE
6 6     He looks â€¦        nostalgia FALSE FALSE     FALSE   FALSE    FALSE    TRUE

</pre> 
    
</details>


> è¾“å‡ºç»“æœæ˜¾ç¤ºï¼Œè¯¥å¯¹è±¡æ˜¯ä¸€ä¸ª â€œtibbleâ€ â€”â€” è¿™æ˜¯ä¸€ç§ç‰¹æ®Šç±»å‹çš„ ``data.frame`` æ•°æ®ç»“æ„ã€‚æˆ‘ä»¬å¯ä»¥æŸ¥çœ‹è¯¥æ•°æ®æ¡†å‰å…­è¡Œçš„å†…å®¹ã€‚å…¶ä¸­ï¼Œåä¸º ``text`` çš„åˆ—åŒ…å«äº† Reddit è¯„è®ºçš„æ­£æ–‡æ–‡æœ¬ã€‚


2. è¯·ä½¿ç”¨ ``corpus()`` å‡½æ•°å¯¹è¿™ç»„æ–‡æœ¬æ•°æ®è¿›è¡Œå¤„ç†ï¼Œä»¥åˆ›å»ºä¸€ä¸ªæ–°çš„è¯­æ–™åº“å¯¹è±¡ã€‚``corpus()`` å‡½æ•°çš„ç¬¬ä¸€ä¸ªå‚æ•°åº”ä¸º ``mft_texts`` å¯¹è±¡ï¼›åŒæ—¶ï¼Œè¿˜éœ€è®¾ç½® ``text_field`` ä¸º ``"text"``ï¼Œä»¥ä¾¿ quanteda çŸ¥é“æˆ‘ä»¬æ„Ÿå…´è¶£çš„æ–‡æœ¬å†…å®¹å­˜å‚¨åœ¨å“ªä¸€ä¸ªå˜é‡åˆ—ä¸­ã€‚

```r
mft_corpus <- corpus(mft_texts, text_field = "text")
```
\
3. åœ¨æˆåŠŸæ„å»ºè¯­æ–™åº“å¯¹è±¡ä¹‹åï¼Œè¯·ä½¿ç”¨ summary() å‡½æ•°å¯¹è¯¥è¯­æ–™åº“è¿›è¡Œç®€è¦æè¿°ï¼Œä»¥æŸ¥çœ‹å…¶åŸºæœ¬ä¿¡æ¯å’Œç»“æ„æ‘˜è¦ã€‚æ€è€ƒï¼šåœ¨è¿™äº› subreddit åç§°ä¸­ï¼Œä½ è§‰å¾—å“ªä¸ªæœ€æœ‰è¶£ã€æœ€å…·åˆ›æ„æˆ–æœ€ä»¤äººå‘ç¬‘ï¼Ÿ

```r
summary(mft_corpus)
```

<details>
<summary>Click to show output</summary>

<pre style="overflow-x: auto; max-height: 400px; white-space: pre; font-family: monospace; background-color: #f8f8f8; padding: 1em; border-radius: 6px;">

Corpus consisting of 17886 documents, showing 100 documents:

    Text Types Tokens Sentences ...1           subreddit  care authority
   text1    67    101         7    1           worldnews FALSE     FALSE
   text2    59     72         2    2            politics FALSE      TRUE
   text3    81    177         3    3           worldnews FALSE     FALSE
   text4    65     82         5    4         geopolitics FALSE      TRUE
   text5    22     22         2    5          neoliberal FALSE     FALSE
   text6    21     28         2    6           nostalgia FALSE     FALSE
   text7    22     24         3    7           worldnews  TRUE     FALSE
   text8    41     44         3    8 relationship_advice  TRUE     FALSE
   text9    20     21         1    9       AmItheAsshole FALSE      TRUE
  text10    12     12         2   10            antiwork FALSE     FALSE
  text11    35     43         3   11              europe FALSE     FALSE
  text12    35     40         2   12          confession FALSE     FALSE
  text13    38     43         2   13 relationship_advice  TRUE     FALSE
  text14    46     62         2   14           worldnews  TRUE     FALSE
  text15    57     88         4   15            antiwork FALSE     FALSE
  text16    16     17         1   16           worldnews FALSE     FALSE
  text17    21     22         3   17       AmItheAsshole  TRUE     FALSE
  text18    20     21         3   18          neoliberal FALSE      TRUE
  text19    22     24         1   19            politics FALSE      TRUE
  text20    19     21         3   20          confession FALSE     FALSE
  text21    48     58         1   21            antiwork  TRUE     FALSE
  text22    78    115         4   22            politics FALSE     FALSE
  text23    12     13         1   23        Conservative FALSE     FALSE
  text24    38     66         1   24            antiwork FALSE     FALSE
  text25    18     26         2   25          confession FALSE     FALSE
  text26    22     32         1   26            politics FALSE     FALSE
  text27    70    103         7   27       AmItheAsshole  TRUE     FALSE
  text28    66     92         5   28           worldnews FALSE     FALSE
  text29    43     57         3   29          confession FALSE     FALSE
  text30    35     42         3   30       AmItheAsshole FALSE     FALSE
  text31    44     52         3   31           worldnews  TRUE     FALSE
  text32    31     39         4   32            antiwork FALSE     FALSE
  text33    20     24         2   33            antiwork  TRUE     FALSE
  text34    33     39         2   34            antiwork FALSE      TRUE
  text35    19     24         1   35          confession FALSE     FALSE
  text36    11     14         1   36        Conservative FALSE     FALSE
  text37    21     24         2   37           worldnews FALSE     FALSE
  text38    73    104         6   38 relationship_advice  TRUE      TRUE
  text39    32     41         3   39            antiwork FALSE     FALSE
  text40    73     95         2   40          neoliberal FALSE     FALSE
  text41    27     29         2   41        Conservative FALSE     FALSE
  text42    11     13         1   42            politics FALSE     FALSE
  text43    37     48         2   43              europe FALSE     FALSE
  text44    66    101         6   44           worldnews FALSE     FALSE
  text45    11     13         1   45            antiwork FALSE     FALSE
  text46    50     66         1   46            politics FALSE     FALSE
  text47    41     49         3   47              europe FALSE      TRUE
  text48    13     16         1   48            politics FALSE      TRUE
  text49    41     52         2   49        Conservative FALSE     FALSE
  text50    39     49         3   50              europe FALSE     FALSE
  text51    14     15         1   51 relationship_advice  TRUE     FALSE
  text52    73    110         3   52           nostalgia FALSE     FALSE
  text53    34     39         3   53          confession FALSE     FALSE
  text54    21     22         1   54        Conservative FALSE     FALSE
  text55    30     33         2   55              europe FALSE      TRUE
  text56    20     21         2   56            politics FALSE     FALSE
  text57    13     15         1   57              europe  TRUE     FALSE
  text58    30     42         5   58           worldnews  TRUE      TRUE
  text59    34     40         2   59          neoliberal FALSE     FALSE
  text60    30     38         4   60          confession FALSE     FALSE
  text61    40     44         3   61           nostalgia FALSE     FALSE
  text62    20     25         1   62        Conservative FALSE     FALSE
  text63    33     38         2   63           worldnews  TRUE     FALSE
  text64    21     31         4   64        Conservative FALSE     FALSE
  text65    28     35         1   65          neoliberal  TRUE      TRUE
  text66    13     14         2   66            antiwork FALSE     FALSE
  text67    11     12         1   67            antiwork  TRUE     FALSE
  text68    14     17         2   68          neoliberal FALSE     FALSE
  text69    18     19         1   69            politics FALSE     FALSE
  text70    15     20         1   70          neoliberal FALSE     FALSE
  text71    40     50         1   71           worldnews FALSE     FALSE
  text72    35     45         1   72           nostalgia FALSE     FALSE
  text73    32     43         2   73       AmItheAsshole  TRUE     FALSE
  text74    32     36         3   74              europe FALSE      TRUE
  text75    38     54         5   75 relationship_advice  TRUE     FALSE
  text76    15     18         1   76        Conservative FALSE      TRUE
  text77    24     25         1   77 relationship_advice  TRUE     FALSE
  text78    20     23         1   78        Conservative FALSE     FALSE
  text79    22     24         3   79            antiwork FALSE     FALSE
  text80    17     21         1   80           worldnews FALSE     FALSE
  text81    36     47         4   81 relationship_advice  TRUE     FALSE
  text82    49     68         1   82            antiwork FALSE     FALSE
  text83    67     82         2   83          confession FALSE     FALSE
  text84    26     32         1   84           worldnews FALSE     FALSE
  text85    25     35         2   85            antiwork FALSE     FALSE
  text86    14     16         1   86            antiwork  TRUE     FALSE
  text87    27     28         1   87       AmItheAsshole  TRUE      TRUE
  text88    18     20         1   88       AmItheAsshole FALSE     FALSE
  text89    33     42         3   89           worldnews FALSE      TRUE
  text90    16     20         1   90          neoliberal FALSE     FALSE
  text91    42     55         3   91            antiwork FALSE     FALSE
  text92    26     30         3   92       AmItheAsshole  TRUE     FALSE
  text93    34     47         2   93        Conservative FALSE     FALSE
  text94    22     28         3   94 relationship_advice  TRUE     FALSE
  text95    53     71         5   95          neoliberal FALSE     FALSE
  text96    38     55         3   96        Conservative FALSE     FALSE
  text97    19     21         2   97           worldnews FALSE      TRUE
  text98    32     34         2   98              europe FALSE     FALSE
  text99    13     15         1   99           worldnews FALSE     FALSE
 text100    19     30         2  100           worldnews FALSE     FALSE
 loyalty sanctity fairness non_moral
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE     TRUE     FALSE
    TRUE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE     TRUE     TRUE      TRUE
    TRUE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE     TRUE      TRUE
   FALSE    FALSE     TRUE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE     TRUE     FALSE
   FALSE     TRUE     TRUE      TRUE
   FALSE    FALSE    FALSE      TRUE
    TRUE    FALSE     TRUE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
    TRUE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE     TRUE    FALSE     FALSE
    TRUE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE     TRUE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE     TRUE     TRUE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE     TRUE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE     TRUE     FALSE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE     TRUE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE     TRUE      TRUE
   FALSE    FALSE    FALSE      TRUE
    TRUE    FALSE    FALSE      TRUE
   FALSE     TRUE     TRUE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE     TRUE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE     TRUE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE     TRUE     TRUE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE     TRUE      TRUE
   FALSE    FALSE     TRUE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE     TRUE     FALSE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE     FALSE
   FALSE    FALSE     TRUE     FALSE
   FALSE     TRUE     TRUE     FALSE
    TRUE    FALSE    FALSE     FALSE
   FALSE     TRUE     TRUE     FALSE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE     TRUE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE     TRUE      TRUE
   FALSE    FALSE     TRUE      TRUE
   FALSE    FALSE     TRUE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
   FALSE     TRUE    FALSE      TRUE
    TRUE     TRUE     TRUE     FALSE
   FALSE    FALSE     TRUE      TRUE
    TRUE    FALSE    FALSE     FALSE
   FALSE    FALSE    FALSE      TRUE
   FALSE    FALSE     TRUE      TRUE
   FALSE    FALSE    FALSE     FALSE
   FALSE    FALSE    FALSE      TRUE
    TRUE    FALSE    FALSE      TRUE
   FALSE    FALSE    FALSE      TRUE
</pre>

</details>

\
4. è¯·æ³¨æ„ï¼Œå°½ç®¡æˆ‘ä»¬åœ¨æ„å»ºè¯­æ–™åº“æ—¶æŒ‡å®šäº† ``text_field = "text"``ï¼Œä½†æˆ‘ä»¬å¹¶æ²¡æœ‰ç§»é™¤ä¸æ–‡æœ¬ç›¸å…³çš„å…ƒæ•°æ®ã€‚ä¸ºäº†è®¿é—®è¿™äº›å…¶ä»–å˜é‡ï¼Œæˆ‘ä»¬å¯ä»¥å°† ``docvars()`` å‡½æ•°åº”ç”¨äºæˆ‘ä»¬ä¸Šé¢åˆ›å»ºçš„è¯­æ–™åº“å¯¹è±¡:

```r
head(docvars(mft_corpus))
```
```
...1   subreddit  care authority loyalty sanctity fairness non_moral
1    1   worldnews FALSE     FALSE   FALSE    FALSE    FALSE      TRUE
2    2    politics FALSE      TRUE   FALSE    FALSE    FALSE      TRUE
3    3   worldnews FALSE     FALSE   FALSE    FALSE    FALSE      TRUE
4    4 geopolitics FALSE      TRUE   FALSE    FALSE     TRUE     FALSE
5    5  neoliberal FALSE     FALSE    TRUE    FALSE    FALSE      TRUE
6    6   nostalgia FALSE     FALSE   FALSE    FALSE    FALSE      TRUE
```

## 1.5 Tokenizing texts

ä¸ºäº†ç»Ÿè®¡è¯é¢‘ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦é€šè¿‡ä¸€ä¸ªç§°ä¸ºâ€œåˆ†è¯ï¼ˆtokenizationï¼‰â€çš„è¿‡ç¨‹ï¼Œå°†æ–‡æœ¬æ‹†åˆ†ä¸ºè¯è¯­ï¼ˆæˆ–æ›´é•¿çš„çŸ­è¯­ï¼‰ã€‚è¯·æŸ¥é˜… ``quanteda`` ä¸­å…³äº ``tokens()`` å‡½æ•°çš„æ–‡æ¡£ã€‚

1. å¯¹æˆ‘ä»¬ä¹‹å‰åˆ›å»ºçš„è¯­æ–™åº“å¯¹è±¡ä½¿ç”¨ tokens å‘½ä»¤ï¼Œå¹¶æŸ¥çœ‹å…¶ç»“æœ:

```r
mft_tokens <- tokens(mft_corpus)
head(mft_tokens)
```

<details>
<summary>Click to show output</summary>

<pre style="overflow-x: auto; max-height: 400px; white-space: pre; font-family: monospace; background-color: #f8f8f8; padding: 1em; border-radius: 6px;">
Tokens consisting of 6 documents and 8 docvars.
text1 :
 [1] "Alternative" "Fact"        ":"           "They"        "argued"     
 [6] "a"           "crowd"       "movement"    "around"      "Ms"         
[11] "Le"          "Pen"        
[ ... and 89 more ]

text2 :
 [1] "Dr"            "."             "Robert"        "Jay"          
 [5] "Lifton"        ","             "distinguished" "professor"    
 [9] "emeritus"      "at"            "John"          "Jay"          
[ ... and 60 more ]

text3 :
 [1] "If"      "you"     "prefer"  "not"     "to"      "click"   "on"     
 [8] "Daily"   "Mail"    "sources" ","       "then"   
[ ... and 165 more ]

text4 :
 [1] "Ben"      "Judah"    "details"  "Emmanuel" "Macron's" "nascent" 
 [7] "foreign"  "policy"   "doctrine" "."        "Noting"   "both"    
[ ... and 70 more ]

text5 :
 [1] "Ergo"     ","        "he"       "supports" "Macron"   "but"     
 [7] "doesn't"  "want"     "to"       "say"      "it"       "out"     
[ ... and 10 more ]

text6 :
 [1] "He"      "looks"   "exactly" "the"     "same"    "in"      "Richie" 
 [8] "Rich"    "as"      "he"      "does"    "as"     
[ ... and 16 more ]
</pre> 
    
</details>


2. æ¥ä¸‹æ¥ï¼Œè¯·å°è¯•ä½¿ç”¨ ``tokens()`` å‡½æ•°çš„ä¸€äº›å‚æ•°ï¼Œä¾‹å¦‚ ``remove_punct`` å’Œ ``remove_numbers``:

```r
mft_tokens <- tokens(mft_corpus, remove_punct = TRUE, remove_numbers = TRUE)
head(mft_tokens)
```

<details>
<summary>Click to show output</summary>

<pre style="overflow-x: auto; max-height: 400px; white-space: pre; font-family: monospace; background-color: #f8f8f8; padding: 1em; border-radius: 6px;">
Tokens consisting of 6 documents and 8 docvars.
text1 :
 [1] "Alternative" "Fact"        "They"        "argued"      "a"          
 [6] "crowd"       "movement"    "around"      "Ms"          "Le"         
[11] "Pen"         "had"        
[ ... and 72 more ]

text2 :
 [1] "Dr"            "Robert"        "Jay"           "Lifton"       
 [5] "distinguished" "professor"     "emeritus"      "at"           
 [9] "John"          "Jay"           "College"       "and"          
[ ... and 56 more ]

text3 :
 [1] "If"      "you"     "prefer"  "not"     "to"      "click"   "on"     
 [8] "Daily"   "Mail"    "sources" "then"    "here"   
[ ... and 131 more ]

text4 :
 [1] "Ben"      "Judah"    "details"  "Emmanuel" "Macron's" "nascent" 
 [7] "foreign"  "policy"   "doctrine" "Noting"   "both"     "that"    
[ ... and 65 more ]

text5 :
 [1] "Ergo"     "he"       "supports" "Macron"   "but"      "doesn't" 
 [7] "want"     "to"       "say"      "it"       "out"      "loud"    
[ ... and 8 more ]

text6 :
 [1] "He"      "looks"   "exactly" "the"     "same"    "in"      "Richie" 
 [8] "Rich"    "as"      "he"      "does"    "as"     
[ ... and 12 more ]

</pre> 
    
</details>


## 1.6 å»ºç«‹ä¸€ä¸ª``dfm()``

æ–‡æ¡£-ç‰¹å¾çŸ©é˜µï¼ˆdocument-feature matricesï¼‰æ˜¯å°†æ–‡æœ¬è¡¨ç¤ºä¸ºé‡åŒ–æ•°æ®çš„æ ‡å‡†æ–¹å¼ã€‚å¹¸è¿çš„æ˜¯ï¼Œåœ¨ quanteda ä¸­å°† tokens å¯¹è±¡è½¬æ¢ä¸º dfm éå¸¸ç®€å•ã€‚

1. è¯·ä½¿ç”¨ ``dfm`` å‡½æ•°å¯¹ä½ ä¹‹å‰åˆ›å»ºçš„åˆ†è¯ï¼ˆtokenizedï¼‰å¯¹è±¡æ„å»ºä¸€ä¸ªæ–‡æ¡£-ç‰¹å¾çŸ©é˜µã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ ``?dfm`` é˜…è¯»è¯¥å‡½æ•°çš„å¸®åŠ©æ–‡æ¡£ï¼Œä»¥äº†è§£å¯ç”¨çš„å‚æ•°é€‰é¡¹ã€‚ä¸€æ—¦åˆ›å»ºå®Œæˆ ``dfm``ï¼Œè¯·ä½¿ç”¨ ``topfeatures()`` å‡½æ•°æ¥æŸ¥çœ‹è¯¥çŸ©é˜µä¸­å‡ºç°é¢‘ç‡æœ€é«˜çš„å‰ 20 ä¸ªç‰¹å¾è¯ã€‚ä½ è§‚å¯Ÿåˆ°çš„éƒ½æ˜¯å“ªä¸€ç±»è¯è¯­ï¼Ÿ

```r
mft_dfm <- dfm(mft_tokens)
mft_dfm
```

<details>
<summary>Click to show output</summary>

<pre style="overflow-x: auto; max-height: 400px; white-space: pre; font-family: monospace; background-color: #f8f8f8; padding: 1em; border-radius: 6px;">

Document-feature matrix of: 17,886 documents, 30,419 features (99.91% sparse) and 8 docvars.
       features
docs    alternative fact they argued a crowd movement around ms le
  text1           2    2    1      1 5     2        2      1  1  2
  text2           0    0    0      0 1     0        0      0  0  0
  text3           1    0    1      0 3     0        0      0  0  0
  text4           0    0    0      0 2     0        0      0  0  0
  text5           0    0    0      0 1     0        0      0  0  0
  text6           0    0    0      0 0     0        0      0  0  0
[ reached max_ndoc ... 17,880 more documents, reached max_nfeat ... 30,409 more features ]

</pre> 
    
</details>


```r
topfeatures(mft_dfm, 20)
```
<details>
<summary>Click to show output</summary>

<pre style="overflow-x: auto; max-height: 400px; white-space: pre; font-family: monospace; background-color: #f8f8f8; padding: 1em; border-radius: 6px;">

the    to   and     a    of    is  that     i   you    in   for    it   not 
22026 17337 14025 12792 11252 10653  8757  8681  8518  6972  6380  6190  5358 
 this    be   are  they   but    le  with 
 4601  4549  4494  4149  4109  3861  3635 

</pre> 
    
</details>


> åŸºæœ¬éƒ½æ˜¯åœç”¨è¯ï¼ˆstop wordsï¼‰

2. å°è¯•ä½¿ç”¨ä¸åŒçš„ ``dfm_*`` å‡½æ•°ï¼Œä¾‹å¦‚ ``dfm_wordstem()``ã€``dfm_remove()`` å’Œ ``dfm_trim()``ã€‚è¿™äº›å‡½æ•°å¯ä»¥åœ¨æ–‡æ¡£-ç‰¹å¾çŸ©é˜µæ„å»ºå®Œæˆåï¼Œç”¨äºç¼©å‡å…¶è§„æ¨¡ã€‚å°†å®ƒä»¬ä¾æ¬¡åº”ç”¨äºä½ åœ¨ä¸Šä¸€ä¸ªé—®é¢˜ä¸­åˆ›å»ºçš„ dfm å¯¹è±¡ï¼Œå¹¶è§‚å¯Ÿç‰¹å¾æ•°é‡çš„å˜åŒ–æƒ…å†µã€‚

```r
dim(mft_dfm)
```

```
[1] 17886 30419
```

```r
dim(dfm_wordstem(mft_dfm))
```

```
[1] 17886 21523
```

```r
dim(dfm_remove(mft_dfm, pattern = c("of", "the", "and")))
```

```
[1] 17886 30416
```

```r
dim(dfm_trim(mft_dfm, min_termfreq = 5, min_docfreq = 0.01, termfreq_type = "count", docfreq_type = "prop"))
```

```
[1] 17886   380
```

3. è¯·ä½¿ç”¨ ``dfm_remove()`` å‡½æ•°ä»è¯¥æ•°æ®ä¸­ç§»é™¤è‹±æ–‡åœç”¨è¯ã€‚ä½ å¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤è·å–è‹±æ–‡åœç”¨è¯åˆ—è¡¨ï¼š

```r
stopwords("english")
```

```r
#ç§»é™¤è‹±æ–‡åœç”¨è¯
mft_dfm_nostops <- dfm_remove(mft_dfm, pattern = stopwords("english"))
mft_dfm_nostops
```

<details>
<summary>Click to show output</summary>

<pre style="overflow-x: auto; max-height: 400px; white-space: pre; font-family: monospace; background-color: #f8f8f8; padding: 1em; border-radius: 6px;">
Document-feature matrix of: 17,886 documents, 30,247 features (99.94% sparse) and 8 docvars.
       features
docs    alternative fact argued crowd movement around ms le pen become
  text1           2    2      1     2        2      1  1  2   2      1
  text2           0    0      0     0        0      0  0  0   0      0
  text3           1    0      0     0        0      0  0  0   0      0
  text4           0    0      0     0        0      0  0  0   0      0
  text5           0    0      0     0        0      0  0  0   0      0
  text6           0    0      0     0        0      0  0  0   0      0
[ reached max_ndoc ... 17,880 more documents, reached max_nfeat ... 30,237 more features ]
</pre> 
    
</details>


## 1.7 Pipes

åœ¨è®²åº§ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº† ``%>%`` è¿™ä¸ªâ€œç®¡é“â€æ“ä½œç¬¦ï¼Œå®ƒå¯ä»¥å°†å¤šä¸ªå‡½æ•°è¿æ¥èµ·æ¥ï¼Œä½¿å¾—ä¸€ä¸ªå‡½æ•°çš„è¾“å‡ºå¯ä»¥ç›´æ¥ä½œä¸ºä¸‹ä¸€ä¸ªå‡½æ•°çš„è¾“å…¥ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™ç§ç®¡é“è¯­æ³•æ¥ç®€åŒ–ä»£ç ï¼Œå¹¶ä½¿å…¶æ›´æ˜“é˜…è¯»ã€‚

ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç®¡é“æ“ä½œç¬¦ï¼Œå°†å…ˆå‰åˆ†åˆ«è¿›è¡Œçš„è¯­æ–™åº“æ„å»ºä¸åˆ†è¯æ­¥éª¤åˆå¹¶ä¸ºä¸€è¡Œä»£ç ï¼š

```r
mft_tokens <- mft_texts %>% # Take the original data object
  corpus(text_field = "text") %>% # ...convert to a corpus
  tokens(remove_punct = TRUE) #...and then tokenize

mft_tokens[1]
```

<details>
<summary>Click to show output</summary>

<pre style="overflow-x: auto; max-height: 400px; white-space: pre; font-family: monospace; background-color: #f8f8f8; padding: 1em; border-radius: 6px;">
Tokens consisting of 1 document and 8 docvars.
text1 :
 [1] "Alternative" "Fact"        "They"        "argued"      "a"          
 [6] "crowd"       "movement"    "around"      "Ms"          "Le"         
[11] "Pen"         "had"        
[ ... and 72 more ]
</pre> 
    
</details>


1. ä½¿ç”¨ ``%>%`` ç®¡é“æ“ä½œç¬¦ç¼–å†™çš„ R è¯­è¨€ä»£ç ï¼Œä¾æ¬¡å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼ša) åˆ›å»ºè¯­æ–™åº“; b) å¯¹æ–‡æœ¬è¿›è¡Œåˆ†è¯; c) æ„å»ºæ–‡æ¡£-ç‰¹å¾çŸ©é˜µï¼ˆdfmï¼‰; d) ç§»é™¤åœç”¨è¯; e) è¾“å‡ºå‡ºç°é¢‘ç‡æœ€é«˜çš„ç‰¹å¾è¯:

```r
mft_texts %>%                           # è·å–åŸå§‹æ•°æ®å¯¹è±¡
  corpus(text_field = "text") %>%       # è½¬æ¢ä¸ºè¯­æ–™åº“
  tokens(remove_punct = TRUE) %>%       # åˆ†è¯åŒ–
  dfm() %>%                             #æ„å»ºæ–‡æ¡£-ç‰¹å¾çŸ©é˜µï¼ˆdfmï¼‰
  dfm_remove(pattern = stopwords("english")) %>% # ç§»é™¤åœç”¨è¯
  topfeatures()                         # è¾“å‡ºå‡ºç°é¢‘ç‡æœ€é«˜çš„ç‰¹å¾è¯
```

<details>
<summary>Click to show output</summary>

<pre style="overflow-x: auto; max-height: 400px; white-space: pre; font-family: monospace; background-color: #f8f8f8; padding: 1em; border-radius: 6px;">
le    pen macron people   like   just    can  think    get  trump 
  3861   3517   3307   3124   2967   2584   1812   1684   1460   1367 
</pre> 
    
</details>  



## 1.8 æè¿°æ€§ç»Ÿè®¡

1. ä½¿ç”¨ ``ntoken()`` å‡½æ•°æ¥ç»Ÿè®¡è¯­æ–™åº“ä¸­æ¯æ¡æ–‡æœ¬çš„è¯å…ƒæ•°é‡ã€‚å°†è¯¥å‡½æ•°çš„è¾“å‡ºèµ‹å€¼ç»™ä¸€ä¸ªæ–°å¯¹è±¡ï¼Œä»¥ä¾¿åç»­ä½¿ç”¨:

```r
mft_n_words <- ntoken(mft_corpus)
```


2. ä½¿ç”¨ ``hist()`` å‡½æ•°ç»˜åˆ¶ç›´æ–¹å›¾ï¼Œä»¥å±•ç¤ºè¯­æ–™åº“ä¸­å„æ–‡æ¡£é•¿åº¦ï¼ˆä»¥è¯å…ƒæ•°è®¡ï¼‰çš„åˆ†å¸ƒæƒ…å†µã€‚åŒæ—¶ï¼Œä½¿ç”¨ ``summary()`` å‡½æ•°æŠ¥å‘Šé›†ä¸­è¶‹åŠ¿çš„ç›¸å…³ç»Ÿè®¡é‡:

```r
hist(mft_n_words)
```
<details>
<summary>Click to show figure</summary>

<img src="https://raw.githubusercontent.com/leondong98/Text-Analysis-Workshop/main/images/1-1.png" width="700"/> 


</details>

```r
summary(mft_n_words)
```

```
 Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   7.00   20.00   31.00   39.09   53.00  177.00 
```

> Reddit è¯­æ–™åº“ä¸­è¯„è®ºçš„ä¸­ä½é•¿åº¦ä¸º 31 ä¸ªè¯ã€‚ç»˜åˆ¶çš„å›¾å½¢è¡¨æ˜ï¼Œè¯¥è¯­æ–™åº“ä¸­çš„æ–‡æ¡£é•¿åº¦åˆ†å¸ƒå‘ˆæ­£åæ€ï¼ˆpositively skewedï¼‰ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œå¤§å¤šæ•°è¯„è®ºè¾ƒçŸ­ï¼Œåˆ†å¸ƒçš„ä¸»ä½“é›†ä¸­åœ¨å·¦ä¾§ï¼Œè€Œå³å°¾è¾ƒé•¿ï¼Œè¡¨æ˜å­˜åœ¨å°‘é‡ç¯‡å¹…è¾ƒé•¿çš„è¯„è®ºã€‚

### 1.8.1 åˆ›å»ºDictionary

è¯å…¸ï¼ˆdictionaryï¼‰æ˜¯å…·ååˆ—è¡¨ï¼ˆnamed listï¼‰ï¼Œç”±â€œé”®ï¼ˆkeyï¼‰â€ä¸ä¸€ç»„å¯¹åº”æ¡ç›®ç»„æˆï¼Œè¿™äº›æ¡ç›®å®šä¹‰äº†è¯¥é”®çš„ç­‰ä»·ç±»ã€‚åœ¨ ``quanteda`` ä¸­ï¼Œè¯å…¸å¯é€šè¿‡ ``dictionary()`` å‡½æ•°åˆ›å»ºã€‚è¯¥å‡½æ•°çš„è¾“å…¥æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼ˆlistï¼‰ï¼Œå…¶ä¸­åŒ…å«è‹¥å¹²å…·åçš„å­—ç¬¦å‘é‡ï¼ˆnamed character vectorsï¼‰ã€‚

ä¾‹å¦‚ï¼Œå‡è®¾æˆ‘ä»¬å¸Œæœ›æ„å»ºä¸€ä¸ªç®€å•çš„è¯å…¸ï¼Œç”¨äºè¡¡é‡ä¸ä¸¤é—¨è¯¾ç¨‹ç›¸å…³çš„è¯è¯­ï¼šé‡åŒ–æ–‡æœ¬åˆ†æï¼ˆquantitative text analysisï¼‰ä¸å› æœæ¨æ–­ï¼ˆcausal inferenceï¼‰ã€‚æˆ‘ä»¬å¯ä»¥é¦–å…ˆä¸ºæ¯ä¸ªæ¦‚å¿µåˆ›å»ºä¸€ç»„ç›¸å…³è¯æ±‡çš„å‘é‡ï¼Œå¹¶å°†å…¶å­˜å‚¨åœ¨ä¸€ä¸ªåˆ—è¡¨ä¸­ï¼š

```r
teaching_dictionary_list <- list(qta = c("quantitative", "text", "analysis", "document", "feature", "matrix"),
                                 causal = c("potential", "outcomes", "framework", "counterfactual"))
```

ç„¶åæˆ‘ä»¬å°†è¯¥å‘é‡ä¼ é€’ç»™ dictionary() å‡½æ•°ï¼š

```r
teaching_dictionary <- dictionary(teaching_dictionary_list)
teaching_dictionary
```

```
Dictionary object with 2 key entries.
- [qta]:
  - quantitative, text, analysis, document, feature, matrix
- [causal]:
  - potential, outcomes, framework, counterfactual
```

æˆ‘ä»¬å½“ç„¶å¯ä»¥æ‰©å±•ç±»åˆ«çš„æ•°é‡ï¼Œå¹¶ä¸ºæ¯ä¸ªç±»åˆ«æ·»åŠ æ›´å¤šè¯è¯­ã€‚

åœ¨å¼€å§‹ç¼–ç ç»ƒä¹ ä¹‹å‰ï¼Œè¯·å…ˆæŸ¥çœ‹ ``mft_dictionary.csv`` æ–‡ä»¶ã€‚ä½ è®¤ä¸ºæ¯ä¸ªé“å¾·åŸºç¡€æ‰€å…³è”çš„è¯è¯­æ˜¯å¦åˆç†ï¼Ÿæ˜¯å¦æœ‰æŸäº›è¯è¯­çœ‹èµ·æ¥ä¸å¤ªæ°å½“ï¼Ÿè¯·è®°ä½ï¼Œæ„å»ºè¯å…¸åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šä¾èµ–ä¸»è§‚åˆ¤æ–­ï¼Œæ‰€é€‰è¯æ±‡çš„èŒƒå›´ä¸å†…å®¹ä¼šå¯¹ä½ æ‰€è¿›è¡Œçš„ä»»ä½•åˆ†æç»“æœäº§ç”Ÿæ˜¾è‘—å½±å“ï¼

1. ä»â€¯``mft_dictionary_words``â€¯æ•°æ®ä¸­çš„è¯æ±‡åˆ›å»ºä¸€ä¸ª quanteda è¯å…¸å¯¹è±¡ã€‚ä½ çš„è¯å…¸åº”åŒ…å«ä¸¤ä¸ªç±»åˆ«â€”â€”ä¸€ä¸ªå¯¹åº” â€œcareâ€(å…³å¿ƒ)ï¼Œå¦ä¸€ä¸ªå¯¹åº” â€œsanctityâ€ï¼ˆç¥åœ£ï¼‰ï¼š

```r
mft_dictionary_list <- list(
  care = mft_dictionary_words$word[mft_dictionary_words$foundation == "care"],
  sanctity = mft_dictionary_words$word[mft_dictionary_words$foundation == "sanctity"]
  )

mft_dictionary <- dictionary(mft_dictionary_list)
mft_dictionary
```

```
Dictionary object with 2 key entries.
- [care]:
  - alleviate, alleviated, alleviates, alleviating, alleviation, altruism, altruist, beneficence, beneficiary, benefit, benefits, benefitted, benefitting, benevolence, benevolent, care, cared, caregiver, cares, caring [ ... and 444 more ]
- [sanctity]:
  - abstinance, abstinence, allah, almighty, angel, apostle, apostles, atone, atoned, atonement, atones, atoning, beatification, beatify, beatifying, bible, bibles, biblical, bless, blessed [ ... and 640 more ]
```

2. ä½¿ç”¨ä½ åœ¨ä¸Šä¸€ä¸ªé—®é¢˜ä¸­åˆ›å»ºçš„è¯å…¸ï¼Œå¹¶å°†å…¶åº”ç”¨äºä½ åœ¨æœ¬æ¬¡ä½œä¸šå‰é¢åˆ›å»ºçš„æ–‡æ¡£-ç‰¹å¾çŸ©é˜µã€‚ä¸ºæ­¤ï¼Œä½ éœ€è¦ä½¿ç”¨ ``dfm_lookup()`` å‡½æ•°ã€‚(å¦‚æœéœ€è¦å¸®åŠ©ï¼Œå¯ä»¥é˜…è¯¥å‡½æ•°çš„å¸®åŠ©æ–‡æ¡£``?dfm_lookup``ï¼‰

```r
mft_dfm_dictionary <- dfm_lookup(mft_dfm, mft_dictionary)
mft_dfm_dictionary
```
<details>
<summary>Click to show output</summary>

<pre style="overflow-x: auto; max-height: 400px; white-space: pre; font-family: monospace; background-color: #f8f8f8; padding: 1em; border-radius: 6px;">
Document-feature matrix of: 17,886 documents, 2 features (78.13% sparse) and 8 docvars.
       features
docs    care sanctity
  text1    0        1
  text2    1        0
  text3    1        0
  text4    1        0
  text5    0        1
  text6    0        0
[ reached max_ndoc ... 17,880 more documents ]
</pre> 
    
</details>  


3. ä½ åˆšåˆšåˆ›å»ºçš„è¯å…¸-æ–‡æ¡£çŸ©é˜µï¼ˆdictionary-dfmï¼‰è®°å½•äº†æ¯æ¡æ–‡æœ¬ä¸­ä¸æ¯ä¸ªé“å¾·åŸºç¡€ç±»åˆ«ç›¸å…³çš„è¯æ±‡æ•°é‡ã€‚ç„¶è€Œï¼Œæ­£å¦‚æˆ‘ä»¬ä¹‹å‰æ‰€è§ï¼Œ**å¹¶éæ‰€æœ‰æ–‡æœ¬çš„è¯æ•°éƒ½ç›¸åŒ**ã€‚è¯·åˆ›å»ºè¯¥è¯å…¸-æ–‡æ¡£çŸ©é˜µçš„ä¸€ä¸ªæ–°ç‰ˆæœ¬ï¼Œå…¶ä¸­è®°å½•çš„æ˜¯æ¯æ¡æ–‡æœ¬ä¸­ä¸å„é“å¾·åŸºç¡€ç±»åˆ«ç›¸å…³çš„è¯æ±‡å æ€»è¯æ•°çš„æ¯”ä¾‹ã€‚

```r
mft_dfm_dictionary_proportions <- mft_dfm_dictionary/mft_n_words
```

4. å°†æ¯ä¸ªé“å¾·åŸºç¡€ç±»åˆ«çš„è¯å…¸å¾—åˆ†å­˜å‚¨ä¸ºæ–°çš„å˜é‡ï¼Œæ·»åŠ åˆ°åŸå§‹çš„ ``mft_texts`` æ•°æ®æ¡†ä¸­ã€‚ä½ éœ€è¦ä½¿ç”¨ ``as.numeric`` å‡½æ•°ï¼Œå°† dfm ä¸­çš„æ¯ä¸€åˆ—å¼ºåˆ¶è½¬æ¢ä¸ºé€‚åˆå­˜å‚¨åœ¨ data.frame ä¸­çš„æ ¼å¼:

```r
mft_texts$care_dictionary <- as.numeric(mft_dfm_dictionary_proportions[,1])
mft_texts$sanctity_dictionary <- as.numeric(mft_dfm_dictionary_proportions[,2])
```

> è¯·æ³¨æ„ï¼Œè¿™é‡Œçš„ä»£ç åªæ˜¯å°†åº”ç”¨è¯å…¸åçš„è¾“å‡ºç»“æœèµ‹å€¼ç»™ ``mft_texts`` æ•°æ®æ¡†ã€‚è¿™åªæ˜¯ä¸ºäº†ä½¿åç»­çš„åˆ†ææ­¥éª¤æ›´ä¸ºç®€ä¾¿ã€‚


### 1.8.2 æœ‰æ•ˆæ€§æ£€éªŒ

ç°åœ¨æˆ‘ä»¬å·²ç»æ„å»ºå¥½äº†è¯å…¸æŒ‡æ ‡ï¼Œæ¥ä¸‹æ¥å°†è¿›è¡Œä¸€äº›åŸºæœ¬çš„æ•ˆåº¦æ£€éªŒã€‚æˆ‘ä»¬å°†ä»ç›´æ¥æ£€æŸ¥åœ¨å„ä¸ªé“å¾·åŸºç¡€ç±»åˆ«ä¸­è¢«è¯å…¸èµ‹äºˆé«˜åˆ†çš„æ–‡æœ¬å¼€å§‹ã€‚

ä¸ºæ­¤ï¼Œæˆ‘ä»¬éœ€è¦æ ¹æ®è¯å…¸åˆ†ææ‰€èµ‹äºˆçš„åˆ†å€¼å¯¹æ–‡æœ¬è¿›è¡Œæ’åºã€‚ä¾‹å¦‚ï¼Œå¯¹äº â€œcareâ€ åŸºç¡€ï¼Œå¯ä»¥ä½¿ç”¨å¦‚ä¸‹ä»£ç ï¼š

```r
mft_texts$text[order(mft_texts$care_dictionary, decreasing = TRUE)][1:5]
```
> - æ–¹æ‹¬å·è¿ç®—ç¬¦``ï¼ˆ[]ï¼‰``å…è®¸æˆ‘ä»¬å¯¹ ``mft_texts$text`` å˜é‡è¿›è¡Œå­é›†æå–;
>  - ``order()`` å‡½æ•°æ ¹æ® ``mft_texts$care_dictionary`` å˜é‡çš„æ•°å€¼å¯¹è§‚æµ‹è¿›è¡Œæ’åºï¼Œå‚æ•° ``decreasing = TRUE`` è¡¨ç¤ºæŒ‰ä»å¤§åˆ°å°çš„é¡ºåºæ’åˆ—ã€‚

1. åœ¨â€¯careâ€¯å’Œâ€¯sanctityâ€¯ä¸¤ä¸ªé“å¾·åŸºç¡€ç±»åˆ«ä¸­ï¼Œè¯å…¸å¾—åˆ†æœ€é«˜çš„å‰ 5 æ¡æ–‡æœ¬åˆ†åˆ«æ˜¯å“ªäº›ï¼Ÿ

```r
mft_texts$text[order(mft_texts$care_dictionary, decreasing = TRUE)][1:5]
```

<details>
<summary>Click to show output</summary>

<pre style="overflow-x: auto; max-height: 400px; white-space: pre; font-family: monospace; background-color: #f8f8f8; padding: 1em; border-radius: 6px;">
[1] "i doubt she'd want \"help\" from a childhood bully ğŸ™„"
[2] "We are talking about threats to human safety, not threats to property."
[3] "What guarantees adoptive parents would have been loving? That the child wouldnâ€™t suffer" 
[4] "The dress design didnâ€™t have anything to do with child sexual assault victims. https://www.papermag.com/alexander-mcqueen-dancing-girls-dress-2645945769.html"
[5] "This right here. Threatening violence of any kind is not ok, sexual rape violence SO not ok."                                                                 
</pre> 
    
</details>  
    
```r
mft_texts$text[order(mft_texts$sanctity_dictionary, decreasing = TRUE)][1:5]
```

<details>
<summary>Click to show output</summary>

<pre style="overflow-x: auto; max-height: 400px; white-space: pre; font-family: monospace; background-color: #f8f8f8; padding: 1em; border-radius: 6px;">
[1] "hot fucking damn macron this last bit was inspiring as hell"   
[2] "Fuck you. Seriously, fuck you. Get your shit together you fucking junkie."
[3] "Hell yeah! Thatâ€™s some hardcore nostalgia right there god DAMN."          
[4] "This is so fucking sad. I hate this god damned country"         
[5] "Holy fuck. This makes OP TA forever. How fucking awful."                                                                         
</pre> 
    
</details> 

2. é˜…è¯»ä¸ care å’Œ sanctity ä¸¤ä¸ªé“å¾·åŸºç¡€æœ€å¼ºç›¸å…³çš„æ–‡æœ¬ã€‚ä½ è®¤ä¸ºè¿™äº›è¯å…¸æ˜¯å¦å‡†ç¡®æ•æ‰äº† â€œå…³æ€€â€ ä¸ â€œç¥åœ£â€ è¿™ä¸¤ä¸ªæ¦‚å¿µï¼Ÿ

> åœ¨ä¸€äº›æƒ…å†µä¸‹ï¼Œè¿™äº›æ–‡æœ¬ä¸ç›¸åº”çš„é“å¾·åŸºç¡€ç±»åˆ«çš„å…³è”ä¼¼ä¹æ˜¯åˆç†çš„ã€‚ä¾‹å¦‚ï¼Œè®¸å¤šä¸ â€œcareâ€ ç›¸å…³çš„æ–‡æœ¬ç¡®å®æ¶‰åŠå¯¹ä»–äººä¼¤å®³çš„æè¿°ã€‚
> 
> ä½†åœ¨å…¶ä»–æƒ…å†µä¸‹ï¼Œè¯å…¸ä¼¼ä¹æ•æ‰åˆ°çš„å†…å®¹å¹¶ä¸å‡†ç¡®ã€‚ä¾‹å¦‚ï¼Œæ‰€æœ‰ä¸ â€œsanctityâ€ ç›¸å…³çš„é«˜åˆ†æ–‡æœ¬å‡ ä¹éƒ½æ˜¯å› ä¸ºåŒ…å«è„è¯ã€‚è™½ç„¶å’’éª‚è¡Œä¸ºå¯èƒ½åœ¨æŸç§ç¨‹åº¦ä¸Šä¸å¯¹ç¥åœ£è®®é¢˜çš„é“å¾·æ•æ„Ÿæ€§ç›¸å…³ï¼Œä½†å®ƒæœ¬èº«å¹¶ä¸æ„æˆå¯¹â€œç¥åœ£â€æ¦‚å¿µçš„å®è´¨æ€§è¡¨è¾¾ï¼Œå› æ­¤è¿™æç¤ºæˆ‘ä»¬ï¼šsanctity è¯å…¸å¯èƒ½ä»éœ€æ”¹è¿›ã€‚

3. ``mft_texts`` å¯¹è±¡ä¸­åŒ…å«äº†ä¸€ç³»åˆ—å˜é‡ï¼Œè®°å½•äº†æ¯æ¡æ–‡æœ¬ç”±äººå·¥æ ‡æ³¨æ‰€å½’ç±»çš„é“å¾·åŸºç¡€ç±»åˆ«ã€‚è¯·ä½¿ç”¨ ``table()`` å‡½æ•°åˆ›å»ºä¸€ä¸ªæ··æ·†çŸ©é˜µ (confusion matrix)ï¼Œä»¥æ¯”è¾ƒäººå·¥æ ‡æ³¨ç»“æœä¸è¯å…¸åˆ†æç”Ÿæˆçš„å¾—åˆ†ä¹‹é—´çš„ä¸€è‡´æ€§:

```r
care_confusion <- table( 
  dictionary = mft_texts$care_dictionary > 0,
  human_coding = mft_texts$care)
care_confusion
```

```
          human_coding
dictionary FALSE  TRUE
     FALSE 11248  2553
     TRUE   1898  2187
```

```r
sanctity_confusion <- table(
  dictionary = mft_texts$sanctity_dictionary > 0,
  human_coding = mft_texts$sanctity)
sanctity_confusion
```

```
          human_coding
dictionary FALSE  TRUE
     FALSE 13268   878
     TRUE   2871   869
```

4. å¯¹äºæ¯ä¸ªé“å¾·åŸºç¡€ç±»åˆ«ï¼Œåˆ†ç±»å™¨çš„å‡†ç¡®ç‡æ˜¯å¤šå°‘ï¼Ÿï¼ˆå¦‚æœä½ å¿˜è®°äº†å¦‚ä½•è®¡ç®—ï¼Œè¯·æŸ¥çœ‹Lectureè®²ä¹‰ï¼‰

```r
# Care
(2187 + 11248)/(2187 + 11248 + 2553 + 1898)
```
```
[1] 0.7511461
```

```r
# Sanctity
(869 + 13268)/(869 + 13268 + 2871 + 878)
```

```
[1] 0.7903947
```

5. å¯¹äºæ¯ä¸ªé“å¾·åŸºç¡€ç±»åˆ«ï¼Œåˆ†ç±»å™¨çš„çµæ•åº¦ï¼ˆsensitivityï¼‰æ˜¯å¤šå°‘ï¼Ÿ

```r
# Care
(2187)/(2187 + 2553)
```

```
[1] 0.4613924
```

```r
# Sanctity
869/(869 + 878)
```

```
[1] 0.4974242
```

6. å¯¹äºæ¯ä¸ªé“å¾·åŸºç¡€ç±»åˆ«ï¼Œåˆ†ç±»å™¨çš„ç‰¹å¼‚åº¦ï¼ˆspecificityï¼‰æ˜¯å¤šå°‘ï¼Ÿ
```r
# Care
(11248)/(11248 + 1898)
```

```
[1] 0.8556215
```

```r
# Sanctity
13268/(13268 + 2871)
```

```
[1] 0.8221079
```

7. æ ¹æ®è¿™äº›æ•°å€¼ï¼Œæˆ‘ä»¬çš„è¯å…¸åœ¨åˆ†ç±»ä»»åŠ¡ä¸­çš„è¡¨ç°å¦‚ä½•ï¼Ÿ

> è™½ç„¶æ•´ä½“çš„**å‡†ç¡®ç‡ï¼ˆaccuracyï¼‰çœ‹èµ·æ¥ç›¸å¯¹è¾ƒé«˜ï¼Œä½†ä»çµæ•åº¦ï¼ˆsensitivityï¼‰**å¾—åˆ†æ¥çœ‹ï¼Œè¯å…¸åœ¨è¯†åˆ«çœŸæ­£çš„ â€œcareâ€ å’Œ â€œsanctityâ€ ç¼–ç æ–‡æœ¬æ–¹é¢çš„è¡¨ç°å…¶å®å¹¶ä¸ç†æƒ³ã€‚
> 
> å…·ä½“è€Œè¨€ï¼Œè¯å…¸å¯¹äºè¿™ä¸¤ä¸ªç±»åˆ«éƒ½æœªèƒ½è¯†åˆ«å‡º 50% ä»¥ä¸Šçš„çœŸæ­£é˜³æ€§æ ·æœ¬ï¼ˆtrue positivesï¼‰ã€‚æ¢å¥è¯è¯´ï¼Œè™½ç„¶è¯å…¸åœ¨å¤šæ•°æƒ…å†µä¸‹å¯èƒ½é¿å…äº†é”™è¯¯åˆ†ç±»ï¼Œä½†å´æ¼æ‰äº†å¤§é‡çœŸæ­£å…·æœ‰â€œå…³æ€€â€æˆ–â€œç¥åœ£â€ç‰¹å¾çš„æ–‡æœ¬ã€‚
> 
> è¿™ç§æƒ…å†µæœ‰äº›ç±»ä¼¼äºä¸€ä¸ªå®‰æ£€ç³»ç»Ÿï¼Œå®ƒåœ¨é¿å…è¯¯æŠ¥ï¼ˆä¸æŠŠæ— å®³ç‰©è¯¯åˆ¤ä¸ºå±é™©å“ï¼‰æ–¹é¢åšå¾—ä¸é”™ï¼Œä½†å´é¢‘ç¹æ¼æ£€çœŸæ­£çš„å±é™©å“ã€‚è¿™å¯¹ç ”ç©¶è€…æ¥è¯´æ˜¯ä¸€ä¸ªè­¦ç¤ºï¼šè¯å…¸è™½ç„¶æä¾›äº†ä¸€ç§é«˜æ•ˆçš„é‡åŒ–æ–¹æ³•ï¼Œä½†åœ¨è¦†ç›–å¤æ‚è¯­ä¹‰å’Œç»†å¾®é“å¾·è¡¨è¾¾æ–¹é¢ï¼Œå¯èƒ½å­˜åœ¨ç€ç»“æ„æ€§ä¸è¶³ã€‚

8. é™¤äº†ä»¥ä¸Šè¿™ç§ç›´æ¥æ‰‹ç®—çš„æ–¹å¼ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨â€¯``caret``â€¯ç¨‹åºåŒ…éå¸¸ç®€ä¾¿åœ°è®¡ç®—è¿™äº›ç»Ÿè®¡é‡:

```r
# install.packages("caret") # åªéœ€è¦åœ¨ç¬¬ä¸€æ¬¡è¿è¡Œè¿™è¡Œä»£ç å®‰è£…!
library(caret)

confusionMatrix(care_confusion, positive = "TRUE")
```

<details>
<summary>Click to show output</summary>

<pre style="overflow-x: auto; max-height: 400px; white-space: pre; font-family: monospace; background-color: #f8f8f8; padding: 1em; border-radius: 6px;">
Confusion Matrix and Statistics

          human_coding
dictionary FALSE  TRUE
     FALSE 11248  2553
     TRUE   1898  2187
                                          
               Accuracy : 0.7511          
                 95% CI : (0.7447, 0.7575)
    No Information Rate : 0.735           
    P-Value [Acc > NIR] : 4.343e-07       
                                          
                  Kappa : 0.3317          
                                          
 Mcnemar's Test P-Value : < 2.2e-16       
                                          
            Sensitivity : 0.4614          
            Specificity : 0.8556          
         Pos Pred Value : 0.5354          
         Neg Pred Value : 0.8150          
             Prevalence : 0.2650          
         Detection Rate : 0.1223          
   Detection Prevalence : 0.2284          
      Balanced Accuracy : 0.6585          
                                          
       'Positive' Class : TRUE          
</pre> 
    
</details> 


```r
confusionMatrix(sanctity_confusion, positive = "TRUE")
```
<details>
<summary>Click to show output</summary>

<pre style="overflow-x: auto; max-height: 400px; white-space: pre; font-family: monospace; background-color: #f8f8f8; padding: 1em; border-radius: 6px;">
Confusion Matrix and Statistics

          human_coding
dictionary FALSE  TRUE
     FALSE 13268   878
     TRUE   2871   869
                                          
               Accuracy : 0.7904          
                 95% CI : (0.7844, 0.7963)
    No Information Rate : 0.9023          
    P-Value [Acc > NIR] : 1               
                                          
                  Kappa : 0.2118          
                                          
 Mcnemar's Test P-Value : <2e-16          
                                          
            Sensitivity : 0.49742         
            Specificity : 0.82211         
         Pos Pred Value : 0.23235         
         Neg Pred Value : 0.93793         
             Prevalence : 0.09767         
         Detection Rate : 0.04859         
   Detection Prevalence : 0.20910         
      Balanced Accuracy : 0.65977         
                                          
       'Positive' Class : TRUE            
                                                                                                                 
</pre> 
    
</details> 



### 1.8.3 åº”ç”¨

åœ¨å®Œæˆä¸Šè¿°éªŒè¯ï¼ˆå°½ç®¡è¯å…¸å¾—åˆ†ä¸äººå·¥ç¼–ç çš„ç›¸å…³æ€§ç›¸å¯¹è¾ƒå¼±ï¼‰ä¹‹åï¼Œæˆ‘ä»¬ç°åœ¨å¯ä»¥ç»§ç»­è¿›è¡Œä¸€ä¸ªç®€å•çš„åº”ç”¨ã€‚

1. è¯·è®¡ç®—æ•°æ®ä¸­ 11 ä¸ª subreddit å„è‡ªçš„ care å’Œ sanctity è¯å…¸å¾—åˆ†çš„å¹³å‡å€¼ï¼š

```r
dictionary_means_by_subreddit <- mft_texts %>%
  group_by(subreddit) %>%
  summarise(care_dictionary = mean(care_dictionary),
            sanctity_dictionary = mean(sanctity_dictionary)) 

dictionary_means_by_subreddit
```

<details>
<summary>Click to show output</summary>

<pre style="overflow-x: auto; max-height: 400px; white-space: pre; font-family: monospace; background-color: #f8f8f8; padding: 1em; border-radius: 6px;">
# A tibble: 11 Ã— 3
   subreddit           care_dictionary sanctity_dictionary
   <chr>                         <dbl>               <dbl>
 1 AmItheAsshole               0.0118              0.00966
 2 Conservative                0.00946             0.0101 
 3 antiwork                    0.0106              0.0120 
 4 confession                  0.0117              0.0127 
 5 europe                      0.00488             0.00453
 6 geopolitics                 0.00394             0.00137
 7 neoliberal                  0.00430             0.00662
 8 nostalgia                   0.00767             0.00959
 9 politics                    0.00923             0.0108 
10 relationship_advice         0.0127              0.0110 
11 worldnews                   0.00651             0.00616
                                                                  
</pre> 
    
</details> 

> ``group_by()`` æ˜¯ä¸€ä¸ªç‰¹æ®Šå‡½æ•°ï¼Œå®ƒå…è®¸æˆ‘ä»¬æ ¹æ®æŒ‡å®šå˜é‡çš„åˆ†ç»„å¯¹æ•°æ®è¿›è¡Œæ“ä½œï¼ˆåœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æŒ‰ subreddit åˆ†ç»„ï¼Œå› ä¸ºæˆ‘ä»¬å¸Œæœ›äº†è§£æ¯ä¸ª subreddit çš„è¯å…¸å¾—åˆ†å‡å€¼ï¼‰
> 
> ``summarise()`` æ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œå¯ç”¨äºå¯¹æ•°æ®è®¡ç®—å„ç§ç±»å‹çš„æ±‡æ€»ç»Ÿè®¡é‡ã€‚

2.å¯¹ä½ åˆšåˆšè®¡ç®—å‡ºçš„ subreddit å¹³å‡å€¼è¿›è¡Œè§£é‡Šï¼Œæˆ–è®¸å°†è¿™äº›ä¿¡æ¯ä»¥å¯è§†åŒ–å›¾å½¢å½¢å¼å±•ç¤ºå‡ºæ¥æ›´ç›´è§‚ï¼š

```r
dictionary_means_by_subreddit %>%
  # å°†æ•°æ®è½¬æ¢æˆ"long format"ä»¥ä¾¿äºç»˜åˆ¶å›¾è¡¨
  pivot_longer(-subreddit) %>%
  # ä½¿ç”¨ ggplot
  ggplot(aes(x = name, y = subreddit, fill = value)) + 
  # ä½¿ç”¨ geom_tile ç»˜åˆ¶ heatmap
  geom_tile() + 
  # ä¿®æ”¹é¢œè‰²è®©å®ƒæ›´ç¾è§‚
  scale_fill_gradient(low = "white", high = "purple") + 
  # å»é™¤åæ ‡è½´
  xlab("") + 
  ylab("") 
```

<details>
<summary>Click to show figure</summary>

<img src="https://raw.githubusercontent.com/leondong98/Text-Analysis-Workshop/main/images/1-2.png" width="700"/>

</details>

> â€œgeopoliticsâ€ å­ç‰ˆå—ä¼¼ä¹å‡ ä¹ä¸åŒ…å«ä¸ sanctityï¼ˆç¥åœ£ï¼‰ ç›¸å…³çš„è¯­è¨€ï¼›è€Œ â€œconfessionâ€ å­ç‰ˆå—åˆ™å¤§é‡ä½¿ç”¨äº†ä¸ sanctity ç›¸å…³çš„è¯æ±‡ã€‚
> 
> ä¸ careï¼ˆå…³æ€€ï¼‰ ç›¸å…³çš„è¯­è¨€åœ¨ â€œrelationship_adviceâ€ å’Œ â€œAmItheAssholeâ€ å­ç‰ˆå—ä¸­åˆ™è¾ƒä¸ºå¸¸è§ã€‚


3. care å’Œ sanctity çš„è¯å…¸å¾—åˆ†ä¹‹é—´çš„ç›¸å…³æ€§æ˜¯å¤šå°‘ï¼Ÿè¿™ä¸¤ä¸ªé“å¾·åŸºç¡€æ˜¯å¦å½¼æ­¤å¯†åˆ‡ç›¸å…³ï¼Ÿ

```r
cor(mft_texts$care_dictionary,mft_texts$sanctity_dictionary)
```

```
[1] 0.03435137
```
> ä¸ï¼ŒåŸºäº care ä¸ sanctity çš„è¯­è¨€ä¹‹é—´çš„ç›¸å…³æ€§éå¸¸ä½ã€‚



## 1.9 è¯¾åæ€è€ƒ

ï¼ˆè¿™ä¸€éƒ¨åˆ†åœ¨æ­£å¼æˆè¯¾ä¸­å¹¶ä¸ä¼šç›´æ¥æä¾›ä»£ç ï¼Œè€Œä¼šåœ¨ç›¸åº”seminarç»“æŸåçš„ç¬¬äºŒå¤©æ›´æ–°ä»£ç å’Œè§£å†³æ–¹æ¡ˆï¼‰

1. è¯·æ¨¡ä»¿seminarä¸­çš„åˆ†æè¿‡ç¨‹ï¼Œå°†å…¶åº”ç”¨åˆ°å…¶ä½™ä¸‰ä¸ªé“å¾·åŸºç¡€ç±»åˆ«ä¸Šï¼šfairnessã€loyalty å’Œ authorityã€‚ç„¶åï¼Œç»˜åˆ¶ä¸€å¼ å›¾è¡¨ï¼Œå±•ç¤ºæ¯ä¸ª subreddit åœ¨æ¯ä¸ªé“å¾·åŸºç¡€ç±»åˆ«ä¸Šçš„å¹³å‡è¯å…¸å¾—åˆ†ã€‚

```r
mft_dictionary_list <- list(
  care = mft_dictionary_words$word[mft_dictionary_words$foundation == "care"],
  sanctity = mft_dictionary_words$word[mft_dictionary_words$foundation == "sanctity"],
  authority = mft_dictionary_words$word[mft_dictionary_words$foundation == "authority"],
  fairness = mft_dictionary_words$word[mft_dictionary_words$foundation == "fairness"],
  loyalty = mft_dictionary_words$word[mft_dictionary_words$foundation == "loyalty"]
  )

mft_dictionary <- dictionary(mft_dictionary_list)

mft_dfm_dictionary <- dfm_lookup(mft_dfm, mft_dictionary)

mft_dfm_dictionary_proportions <- mft_dfm_dictionary/mft_n_words

mft_texts$care_dictionary <- as.numeric(mft_dfm_dictionary_proportions[,1])
mft_texts$sanctity_dictionary <- as.numeric(mft_dfm_dictionary_proportions[,2])
mft_texts$authority_dictionary <- as.numeric(mft_dfm_dictionary_proportions[,3])
mft_texts$fairness_dictionary <- as.numeric(mft_dfm_dictionary_proportions[,4])
mft_texts$loyalty_dictionary <- as.numeric(mft_dfm_dictionary_proportions[,5])

dictionary_means_by_subreddit <- mft_texts %>%
  group_by(subreddit) %>%
  summarise(care_dictionary = mean(care_dictionary),
            sanctity_dictionary = mean(sanctity_dictionary),
            authority_dictionary = mean(authority_dictionary),
            fairness_dictionary = mean(fairness_dictionary),
            loyalty_dictionary = mean(loyalty_dictionary)) 


dictionary_means_by_subreddit %>%
  # Transform the data to "long" format for plotting
  pivot_longer(-subreddit) %>%
  # Use ggplot
  ggplot(aes(x = name, y = subreddit, fill = value)) + 
  # geom_tile creates a heatmap
  geom_tile() + 
  # change the colours to make them prettier
  scale_fill_gradient(low = "white", high = "purple") + 
  # remove the axis labels
  xlab("") + 
  ylab("") 
```
<details>
<summary>Click to show figure</summary>

<img src="https://raw.githubusercontent.com/leondong98/Text-Analysis-Workshop/main/images/1-3.png" width="700"/>

</details>








  

 




