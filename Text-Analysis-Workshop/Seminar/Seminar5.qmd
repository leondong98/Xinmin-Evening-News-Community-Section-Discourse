---
title: 研讨会5：文本作为数据B：词嵌入

---

# 研讨会5：文本作为数据B：词嵌入 

讲座人：Hanxu hanxu.dong.21@ucl.ac.uk

<p>
  <a href="https://pan.baidu.com/s/1widr96E8ZBC0v80lvKpYeg 提取码: b0hs" 
     style="display:inline-block; background-color:#4CAF50; color:white; padding:10px 20px; text-decoration:none; margin-right:10px; border-radius:5px;">
    Seminar data
  </a>
    
## 5.1 相似性、类比与词典扩展

在前几周中，当我们将词语表示为数据时，我们只是简单地计算它们在文档之间和文档内部出现的频率。我们大体上将词语视为**独立的单位**：作为唯一标识某一特定含义的文本字符串，而我们并没有一个自然的相似性概念来将相似的词汇进行归类。

相比之下，**词嵌入（word embeddings）** 方法将语料库中的每个唯一词汇表示为一个密集的实数向量。正如我们在讲座中所讨论的，这些向量实际编码了大量关于词语用法的信息，这些信息可以在社会科学中的各种问题上加以有效利用。

在今天的研讨课中，我们将熟悉 [GloVe 项目](https://nlp.stanford.edu/projects/glove/)中一些预训练的词向量。我们将使用这些向量来探索词语之间的相似性，执行基于类比的任务，并补充我们在讲座二中学习过的基于词典的测量方法。
    
## 5.2 Packages
在开始研讨会时，先下载/加载以下 R 包：

```r
library(tidyverse)
library(quanteda)
# install.packages("text2vec")
library(text2vec)
```
    
## 5.3 数据集

今天我们将使用预训练的 GloVe 词嵌入，这些文件可以从研讨课页面顶部的链接下载。请注意，包含词嵌入的文件非常大！因此，建议你可以提前一天先下载好。

尽管文件体积很大，我们实际上使用的是 GloVe 词嵌入中较小的一个版本，它是在维基百科和新闻数据的组合上训练而成的。这些词嵌入的维度为 300，涵盖约 40 万个词汇。请注意，你也可以从 [GloVe 项目官网](https://nlp.stanford.edu/projects/glove/)中下载更大版本的词嵌入来复现本次练习中的所有任务，但对于我们这里的应用而言，使用更大的模型所带来的差异可能是微乎其微的。
    
## 5.4 词语相似性

1. 使用 ``load()`` 函数将 GloVe 词嵌入加载到 R 中。

<details>
<summary>Reveal Code</summary>
    
```r
load("glove_embeddings.Rdata")
```   
    
</details>

2. 看看 Glove 嵌入对象的大小。这个对象有多少行？有多少列？分别表示了什么？
    
<details>
<summary>Reveal Code</summary>
    
```r
dim(glove)
```

```
[1] 400000    300   
```
    
> 行代表单词。列代表嵌入的维度。
    
</details>
    
3. 写一个函数，用于计算给定词汇与 GloVe 词嵌入对象中所有其他词之间的余弦相似度。你可以使用 ``text2vec`` 包中的 ``sim2()`` 函数来实现此操作。你的函数应包含两个输入参数：
- ``target_word``：你希望计算相似度的目标词
- ``n``：你希望返回的最近邻词的数量（按相似度排序）
该函数将帮助你快速发现与任一词语最相近的词汇，有助于理解词语在向量空间中的语义邻近性。

<details>
<summary>Reveal Code</summary>
    
```r
similarities <- function(target_word, n){

  # 提取目标词的词向量
  target_vector <- glove[which(rownames(glove) %in% target_word),]  
  
  # 计算目标词与其他词之间的余弦相似度
  target_sim <- sim2(glove, matrix(target_vector, nrow = 1))
  
  # 返回与目标词最相近的前 n 个词
  names(sort(target_sim[,1], decreasing = T))[1:n]

}
```   
    
</details>
    
4. 根据你写好的这个函数，找出与下列三个词最相似的前七个词: "quantitative"; "text"; "analysis"(你也可以尝试一些别的词)
 
<details>
<summary>Reveal Code</summary>
    
```r
similarities("quantitative", n = 7)
```  
    
```
[1] "quantitative" "qualitative"  "empirical"    "measurement"  "analysis"    
[6] "methodology"  "analytical"     
```
    
```r
similarities("text", n = 7)
```  
    
```
[1] "text"     "texts"    "document" "read"     "messages" "written"  "copy"       
```

```r
similarities("analysis", n = 7)
```  
    
```
[1] "analysis"    "analyses"    "study"       "data"        "studies"    
[6] "analyzed"    "methodology"      
```
    
</details>
    
## 5.5 词类比

1. 编写一个函数，用于计算形式为 “a is to b as c is to ___” 的类比关系。例如，如果 b 是 “king”，a 是 “man”，c 是 “woman”，那么缺失的词应该是 “queen”。
你的函数需要接受四个参数。前三个参数应对应于类比中包含的词。第四个参数应是一个指定返回最近邻词数量的参数。
 
<details>
<summary>Reveal Code</summary>
    
```r
analogies <- function(a, b, c, n){
  
  # 提取类比任务中三个词的词向量
  a_vec <- glove[which(rownames(glove) == a),]
  b_vec <- glove[which(rownames(glove) == b),]
  c_vec <- glove[which(rownames(glove) == c),]
  
  # 生成类比向量（向量(c) - 向量(a) + 向量(b)）
  target <- c_vec - a_vec + b_vec
  
  # 计算类比向量与所有其他向量之间的余弦相似度
  target_sim <- sim2(glove, matrix(target, nrow = 1))
  
  # 返回与类比向量最相似的前 n 个词
  names(sort(target_sim[,1], decreasing = T))[1:n]

}     
```
    
</details>

2. 使用你上面创建的函数来求解以下类比填空任务的词嵌入答案。
- Einstein is to scientist as Picasso is to ___?
- Arsenal is to football as Yankees is to ___?
- Actor is to theatre as doctor is to ___?

<details>
<summary>Reveal Code</summary>
    
```r
analogies("einstein", "scientist", "picasso", 6)
```
```
[1] "picasso"   "painter"   "painting"  "artist"    "paintings" "scientist"  
```
    
```r
analogies("arsenal", "football", "yankees", 6)
```
```
[1] "baseball"   "yankees"    "sox"        "football"   "basketball"
[6] "braves"   
```
    
```r
analogies("actor", "theatre", "doctor", 6)
```
```
[1] "theatre"  "doctor"   "hospital" "medical"  "theater"  "doctors"   
```
    
</details>
    
3. 尝试一些其他词的类比！
    
## 5.6 词典扩展

在研讨会2中，我们使用了道德基础词典（Moral Foundations Dictionary, MFD）来评估 Reddit 帖子中的道德内容。在本次研讨会中，我们将使用 GloVe 词嵌入来扩展 MFD 中的 “care” 类别。

为完成这一部分任务，你需要再次访问我们在研讨课 2 中使用的文件：
- ``mft_dictionary.csv``
- ``mft_texts.csv``
现在请找到这些文件（如果需要，可以重新下载）一旦找到了这些文件，请将它们加载到 R 中。
    
```r
mft_dictionary_words <- read_csv("mft_dictionary.csv")
mft_texts <- read_csv("mft_texts.csv")
```
    
1. 创建一个包含 MFT 词典中 “Care” 类别词汇的向量。
    
<details>
<summary>Reveal Code</summary>
    
```r
care_words <- mft_dictionary_words$word[mft_dictionary_words$foundation == "care"] 
```
    
</details>
    
2. 从 ``glove`` 中提取与 “care” 类别词汇相关的词嵌入向量。
    
<details>
<summary>Reveal Code</summary>
    
```r
care_embeddings <- glove[rownames(glove) %in% care_words,]
```
    
</details>
    
3. 计算 “care” 词汇的平均嵌入向量。请使用 ``colMeans`` 函数，它可以计算矩阵每一列的均值。
  
<details>
<summary>Reveal Code</summary>
    
```r
care_embeddings_mean <- colMeans(care_embeddings)
```
    
</details>

4. 计算 care 平均向量与 ``glove`` 嵌入对象中所有其他词之间的相似度。为此，再次使用 ``sim2()`` 函数。
    
<details>
<summary>Reveal Code</summary>
    
```r
target_sim <- sim2(x = glove,
                   y = matrix(care_embeddings_mean, nrow = 1))
```
    
</details>

    
5. 哪些是与 care 平均向量具有最高余弦相似度的 500 个词？这些词中有多少在原始词典中？

<details>
<summary>Reveal Code</summary>
    
```r
top500 <- names(sort(target_sim[,1], decreasing = T))[1:500]

table(top500%in%care_words)
```
          
```
FALSE  TRUE 
  386   114        
```
    
</details>
    

6. 检查你在上一步中计算出的前 500 个词中不在原始 care 词典中的词。这些词是否体现了 “care” 的概念？
 
<details>
<summary>Reveal Code</summary>
    
```r
top500[!top500%in%care_words]
```
          
```
  [1] "traumatized"     "victimized"      "cruelly"         "helpless"       
  [5] "innocent"        "unborn"          "sufferings"      "endure"         
  [9] "terrified"       "frightened"      "sick"            "callous"        
 [13] "wronged"         "civilians"       "viciously"       "senseless"      
 [17] "terrorizing"     "frighten"        "beatings"        "horrific"       
 [21] "risking"         "inhumane"        "unspeakable"     "confess"        
 [25] "humiliation"     "defenseless"     "loneliness"      "terrorize"      
 [29] "grief"           "bereaved"        "injustice"       "subjecting"     
 [33] "vengeful"        "innocents"       "misfortune"      "abuse"          
 [37] "neglect"         "plight"          "treating"        "traumatised"    
 [41] "stigmatized"     "oppression"      "starving"        "humiliate"      
 [45] "oftentimes"      "grievous"        "unjustly"        "grieving"       
 [49] "humiliated"      "betrayed"        "spared"          "mutilation"     
 [53] "lest"            "ashamed"         "heinous"         "enemies"        
 [57] "abusive"         "barbaric"        "elderly"         "starve"         
 [61] "fear"            "neglecting"      "terrible"        "deprived"       
 [65] "dignity"         "deprive"         "beings"          "dying"          
 [69] "mercilessly"     "hatred"          "grievously"      "oneself"        
 [73] "vicious"         "succumb"         "feelings"        "schoolmates"    
 [77] "fearful"         "horrible"        "horrifying"      "sparing"        
 [81] "hardships"       "afraid"          "risked"          "indiscriminate" 
 [85] "unnecessarily"   "bystanders"      "heartless"       "shame"          
 [89] "ordeal"          "offends"         "subjected"       "enslavement"    
 [93] "handicapped"     "disturbed"       "humanity"        "sacrificing"    
 [97] "degrading"       "oppressed"       "treat"           "retribution"    
[101] "maiming"         "injure"          "terrify"         "terminally"     
[105] "unbearable"      "betray"          "suicidal"        "pretending"     
[109] "seriously"       "perpetrated"     "destitute"       "maimed"         
[113] "perpetrator"     "insult"          "demeaning"       "depraved"       
[117] "betraying"       "selfishness"     "aiding"          "traumas"        
[121] "taunt"           "brutal"          "belittling"      "sickening"      
[125] "despair"         "needless"        "orphans"         "repress"        
[129] "terrorized"      "hardship"        "scared"          "infirm"         
[133] "husbands"        "savagery"        "townspeople"     "mentally"       
[137] "punishing"       "disciplining"    "sins"            "savagely"       
[141] "escaping"        "teasing"         "sickness"        "distraught"     
[145] "captors"         "pregnant"        "oppress"         "spouse"         
[149] "indignity"       "intolerable"     "intimidated"     "forgiveness"    
[153] "countrymen"      "cursed"          "conscience"      "knowing"        
[157] "trauma"          "deserve"         "punishes"        "strangling"     
[161] "wickedness"      "sinful"          "punished"        "cruelties"      
[165] "helplessness"    "punish"          "disrespect"      "perceived"      
[169] "appalling"       "hysterical"      "bystander"       "disfigurement"  
[173] "treachery"       "homosexuals"     "debilitating"    "evils"          
[177] "taunts"          "vindictive"      "betrayal"        "tolerate"       
[181] "provokes"        "thoughtless"     "avenge"          "intimidate"     
[185] "feel"            "offend"          "despicable"      "needlessly"     
[189] "malnourished"    "sexually"        "tolerating"      "bodily"         
[193] "terrifying"      "passivity"       "abduct"          "betrays"        
[197] "trusting"        "frightening"     "expose"          "misguided"      
[201] "barbarity"       "severely"        "perceive"        "imprison"       
[205] "horrendous"      "depriving"       "sadistic"        "committing"     
[209] "unworthy"        "treated"         "unjust"          "slaughtering"   
[213] "painful"         "debilitated"     "scolding"        "enslave"        
[217] "aftereffects"    "disrespectful"   "victimised"      "awaken"         
[221] "humankind"       "resentful"       "suffocate"       "hypocritical"   
[225] "cowardly"        "fleeing"         "judgmental"      "ridicule"       
[229] "insecurities"    "complicit"       "misery"          "caretakers"     
[233] "detriment"       "physically"      "tenderly"        "habitually"     
[237] "malnutrition"    "punishment"      "misbehaving"     "villagers"      
[241] "emotionally"     "relatives"       "selfish"         "deserving"      
[245] "destitution"     "gravely"         "exposing"        "companionship"  
[249] "squeamish"       "brutally"        "guilt"           "imprisoning"    
[253] "orphaned"        "criminals"       "injustices"      "adolescents"    
[257] "stigma"          "disobedient"     "sacrificed"      "survivors"      
[261] "remorse"         "empathetic"      "wanton"          "insults"        
[265] "unsuspecting"    "enslaving"       "aggression"      "involuntarily"  
[269] "outweighs"       "ignorance"       "screams"         "addicted"       
[273] "ostracized"      "subordinates"    "immoral"         "caregivers"     
[277] "merciless"       "perpetrators"    "powerlessness"   "mutilating"     
[281] "ills"            "depredations"    "stab"            "affection"      
[285] "ill-treatment"   "ill"             "blinded"         "callously"      
[289] "insulted"        "manipulative"    "verbally"        "unintentionally"
[293] "distract"        "illness"         "ungrateful"      "deprivation"    
[297] "pretend"         "undermines"      "disfigured"      "impotent"       
[301] "cursing"         "inconvenience"   "motivates"       "witnessing"     
[305] "aggressors"      "jealousy"        "suffocating"     "children"       
[309] "sacrifices"      "jealous"         "hideous"         "ostracism"      
[313] "perverted"       "horrified"       "insensitive"     "confronting"    
[317] "illnesses"       "befriend"        "scourge"         "willful"        
[321] "repression"      "revenge"         "annoy"           "scarred"        
[325] "curses"          "throats"         "jailers"         "horribly"       
[329] "repressed"       "bigotry"         "excruciating"    "befriending"    
[333] "coerce"          "traumatic"       "ugliness"        "revulsion"      
[337] "exposes"         "patronizing"     "stepmother"      "newborns"       
[341] "indulging"       "promiscuous"     "confront"        "ministering"    
[345] "unconscionable"  "insidious"       "tenderness"      "indifference"   
[349] "gruesome"        "trampling"       "embittered"      "despise"        
[353] "cowardice"       "hopelessness"    "underlings"      "horrors"        
[357] "scold"           "atrocious"       "banish"          "persecutions"   
[361] "brainwashed"     "indignities"     "banishing"       "pretended"      
[365] "abhorrent"       "wrongs"          "genitals"        "counseled"      
[369] "atrocities"      "susceptible"     "ferocity"        "indifferent"    
[373] "autistic"        "deprivations"    "demoralizing"    "unfaithful"     
[377] "transgressions"  "brainwashing"    "ghastly"         "insufferable"   
[381] "taunting"        "pillage"         "believing"       "unconscious"    
[385] "afflicting"      "muggers"        
```
    
</details>
    

7. 你对上一个问题的回答对这种词典扩展方法有何启示？
 
<details>
<summary>Reveal Code</summary>
    
> 这里的核心思想是，使用词嵌入（word embeddings）使我们能够**自动扩展**与某一概念相关的词汇集合，而此前我们是通过手动选定的一组词典词语来进行测量的。

> 这意味着我们可以利用词语之间的相似性信息来补充现有的测量方法。至于这是否会在分类任务中带来性能上的提升，将是下面课后思考中要探讨的主题。
    
</details>
    
## 7.7 课后思考
    
``mft_texts`` 对象中包含了一系列变量，这些变量记录了每条文本由人工标注归属到的道德类别。在今天的课后思考中，你将再次使用基于词典的方法对文本进行打分，并将这些词典分数与人工编码进行比较。如果你忘记了如何应用词典，可以回顾研讨会2的材料。

1. 请创建一个新的词典对象，其中应包含两个类别：
- ``care_original_words``：只包含原始 care 词典中的词语；
- ``care_embedding_words``：包含原始 care 词典词语以及你在上一部分中提取出的前 500 个最相似词语。

<details>
<summary>Reveal Code</summary>
    
```r
# 创建 dfm
mft_dfm <- mft_texts %>% 
  corpus(text_field = "text") %>% 
  tokens(remove_punct = TRUE) %>% 
  dfm() %>%
  dfm_trim(min_termfreq = 5)

# 创建 care 词典
care_dictionary <- dictionary(list(care_original = care_words,
                                   care_embedding = c(top500[!top500%in%care_words], care_words)))
```
    
</details>
    
2. 使用你刚刚构建的词典对 ``mft_texts`` 对象中的文本进行打分。在该对象中创建变量，指示每条文本是否被相应的词典分类为 care 文本（即如果文本中包含该类别词典中的任意词语，则将其分类为 care 文本）。
    
<details>
<summary>Reveal Code</summary>
    
```r
# 使用词典对文本进行打分
care_dfm_dictionary <- dfm_lookup(mft_dfm, care_dictionary)
mft_texts$care_original <- as.numeric(care_dfm_dictionary[,1]) > 0
mft_texts$care_embedding <- as.numeric(care_dfm_dictionary[,2]) > 0
```
    
</details>
    
3. 创建一个混淆矩阵，用于将人工标注与词典打分结果进行比较。你需要分别比较以下两个变量与人工标注的匹配情况：
- ``mft_texts$care_original``：使用原始 care 词典的分类结果
- ``mft_texts$care_embedding``：使用词嵌入扩展后的 care 词典分类结果
然后，通过混淆矩阵评估：哪种方法表现最好 —— 原始词典，还是词嵌入扩展的方法？
    
<details>
<summary>Reveal Code</summary>
    
```r
# 计算混淆矩阵：原始 care 词典
care_original_confusion <- table( 
  dictionary = mft_texts$care_original > 0,
  human_coding = mft_texts$care)

# 计算混淆矩阵：嵌入扩展后的 care 词典
care_embedding_confusion <- table( 
  dictionary = mft_texts$care_embedding > 0,
  human_coding = mft_texts$care)

# 输出原始词典的性能统计
library(caret)
confusionMatrix(care_original_confusion, positive = "TRUE")
```
    
```
Confusion Matrix and Statistics

          human_coding
dictionary FALSE  TRUE
     FALSE 11303  2621
     TRUE   1843  2119
                                         
               Accuracy : 0.7504         
                 95% CI : (0.744, 0.7567)
    No Information Rate : 0.735          
    P-Value [Acc > NIR] : 1.326e-06      
                                         
                  Kappa : 0.3238         
                                         
 Mcnemar's Test P-Value : < 2.2e-16      
                                         
            Sensitivity : 0.4470         
            Specificity : 0.8598         
         Pos Pred Value : 0.5348         
         Neg Pred Value : 0.8118         
             Prevalence : 0.2650         
         Detection Rate : 0.1185         
   Detection Prevalence : 0.2215         
      Balanced Accuracy : 0.6534         
                                         
       'Positive' Class : TRUE        
```
                                   
```r
confusionMatrix(care_embedding_confusion, positive = "TRUE")
```
                                   
```
Confusion Matrix and Statistics

          human_coding
dictionary FALSE  TRUE
     FALSE 10114  1763
     TRUE   3032  2977
                                          
               Accuracy : 0.7319          
                 95% CI : (0.7254, 0.7384)
    No Information Rate : 0.735           
    P-Value [Acc > NIR] : 0.8265          
                                          
                  Kappa : 0.3661          
                                          
 Mcnemar's Test P-Value : <2e-16          
                                          
            Sensitivity : 0.6281          
            Specificity : 0.7694          
         Pos Pred Value : 0.4954          
         Neg Pred Value : 0.8516          
             Prevalence : 0.2650          
         Detection Rate : 0.1664          
   Detection Prevalence : 0.3360          
      Balanced Accuracy : 0.6987          
                                          
       'Positive' Class : TRUE    
```

>  在本例中，当我们引入基于词嵌入相似度扩展出的词语后，预测的准确率略有下降，但分类的敏感性显著提高。这表明，新增的词语在很大程度上提升了我们识别表达“care”概念文本的能力，尽管这也带来了更多的**假阳性结果**（即误将非 care 文本分类为 care）。                              
                                 
</details>
